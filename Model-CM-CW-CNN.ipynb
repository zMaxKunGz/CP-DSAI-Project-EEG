{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Brain Inverders Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braininvaders2015a.dataset import BrainInvaders2015a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainInvaders2015a()\n",
    "\n",
    "def loadData(subject, session = 'session_1', run = 'run_1'):\n",
    "    data = dataset._get_single_subject_data(subject)\n",
    "    data = data[session][run]\n",
    "    # data.set_montage(ten_twenty_montage)\n",
    "    return data\n",
    "\n",
    "data_subjects = []\n",
    "subjects = list(range(1,44))\n",
    "subjects.remove(1)\n",
    "subjects.remove(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_subjects.append(loadData(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import create_info\n",
    "from mne import Epochs, find_events\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def df_to_raw(df):\n",
    "    sfreq = 512\n",
    "    ch_names = list(df.columns)\n",
    "    ch_types = ['eeg'] * (len(df.columns) - 1) + ['stim']\n",
    "    ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "    df = df.T\n",
    "      #mne looks at the tranpose() format\n",
    "    df[:-1] *= 1e-6\n",
    "      #convert from uVolts to Volts (mne assumes Volts data)\n",
    "\n",
    "    info = create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n",
    "\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage(ten_twenty_montage)\n",
    "    return raw\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    \n",
    "    #reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "    #                       grad=4000e-13,    # 4000 fT/cm\n",
    "    #                       eeg=100e-6,       # 150 μV\n",
    "    #                       eog=250e-6)       # 250 μV\n",
    "\n",
    "    reject_criteria = dict(eeg=100e-6)  #most voltage in this range is not brain components\n",
    "\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs\n",
    "  \n",
    "def preprocessing(rawdata, runPCA=False):\n",
    "    # Convert and drop time column\n",
    "    data_ses1_run1_pd = rawdata.to_data_frame()\n",
    "    data_ses1_run1_pd = data_ses1_run1_pd.drop(['time'],axis = 1)\n",
    "    raw = df_to_raw(data_ses1_run1_pd)\n",
    "\n",
    "    # Notch Filter\n",
    "    raw.notch_filter(np.arange(50, 251, 50))\n",
    "\n",
    "    eeg_channels = mne.pick_types(raw.info, eeg=True)\n",
    "    raw.filter(1,24,method = 'iir')\n",
    "\n",
    "\n",
    "    if runPCA:\n",
    "      raw_df = raw.to_data_frame()\n",
    "      X1 = raw_df.drop(['time'],axis = 1)\n",
    "      X = X1.drop(['STI 014'],axis = 1)\n",
    "      y = raw_df['STI 014']\n",
    "      pca = PCA(n_components=32)\n",
    "      X = pca.fit(X.values).transform(X.values)\n",
    "      y1 = y.values.reshape(-1,1)\n",
    "      data = np.hstack((X,y1))\n",
    "      df = pd.DataFrame(data, columns = list(X1.columns))\n",
    "      raw = df_to_raw(df)\n",
    "\n",
    "    event_id = {'NonTarget': 1, 'Target': 2}\n",
    "    tmin = 0.0 #0\n",
    "    tmax = 1.0 #0.5 seconds\n",
    "    picks= eeg_channels\n",
    "    epochs = getEpochs(raw,event_id, tmin, tmax, picks)\n",
    "\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 24 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 24.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "360 events found\n",
      "Event IDs: [1 2]\n",
      "sample drop %:  0.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "X_subjects = []\n",
    "y_subjects = []\n",
    "\n",
    "for data in data_subjects:\n",
    "    X, y = preprocessing(data)    \n",
    "    X_subjects.append(X)\n",
    "    y_subjects.append(y)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshape, Convert to torch, Test/Train Split, and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "def ShapePreparing(X, y, BATCH_SIZE = 32):\n",
    "    X_reshaped = X[:, np.newaxis, :, :]\n",
    "    torch_X_reshaped = torch.from_numpy(X_reshaped)\n",
    "    torch_y = torch.from_numpy(y)\n",
    "\n",
    "    ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "    #Train test split\n",
    "    train_size = int(round(torch_X_reshaped.size()[0] * 0.7))\n",
    "    valid_size = int(round(torch_X_reshaped.size()[0] * 0.1))\n",
    "    test_size = int(round(torch_X_reshaped.size()[0] * 0.2))\n",
    "    sum_size = np.sum([train_size, valid_size, test_size])\n",
    "\n",
    "    # Adjust total size to equal to sample size\n",
    "    while sum_size<torch_X_reshaped.shape[0]:\n",
    "        train_size += 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    while sum_size>torch_X_reshaped.shape[0]:\n",
    "        train_size -= 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    \n",
    "    # Split data\n",
    "    train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size])\n",
    "\n",
    "    #Train set loader\n",
    "    train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    #Validation set loader\n",
    "    valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "\n",
    "    #Test set loader\n",
    "    test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = ShapePreparing(X, y, BATCH_SIZE=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 513])\n",
      "torch.Size([64, 1, 32, 513])\n",
      "torch.Size([64, 1, 32, 513])\n",
      "torch.Size([60, 1, 32, 513])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(train_iterator):\n",
    "    print(images.shape)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM-CW-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_CW_CNN(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, channels, height , width)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CM_CW_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,16,kernel_size=(32,1),stride=(1,1)))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16,16,kernel_size=(1,57),stride=(1,57)))\n",
    "        self.fc = nn.Sequential(nn.Linear(144,144),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(144,48),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(48,12),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(12,3),nn.ReLU(),nn.Dropout(0.0))\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        # print(\"X flatten\",x.shape)\n",
    "        # torch.manual_seed(9999)\n",
    "        x = self.fc(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, _print=False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "\n",
    "    trues = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "        \n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        if _print:\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted)\n",
    "        predicteds.append(predicted)\n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        if _print:\n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)\n",
    "        trues.append(labels)\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc, predicteds, trues\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)\n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "\n",
    "def Training(model, train_iterator, valid_iterator, N_EPOCHS = 50, saveName=None):\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    start_time_train = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label= evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Trainning:\")\n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            if saveName != None:\n",
    "                directory = 'results/CM_CW_CNN/'\n",
    "                fileName = saveName+'.pth.tar'\n",
    "                path = directory+fileName\n",
    "                while True:\n",
    "                    try:\n",
    "                        torch.save(model.state_dict(), path)\n",
    "                        # print(\"Model:{} saved.\".format(fileName))\n",
    "                        break\n",
    "                    except:\n",
    "                        os.mkdir(directory)\n",
    "                        open(path, 'w')\n",
    "    training_mins, training_secs = epoch_time(start_time_train, time.time())\n",
    "    return train_losses, valid_losses, train_accs, valid_accs, training_mins, training_secs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning:\n",
      "Epoch: 50 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.112 | Train Acc: 95.24%\n",
      "\t Val. Loss: 3.252 |  Val. Acc: 80.56%\n"
     ]
    }
   ],
   "source": [
    "train_losses_list = []\n",
    "train_accs_list = []\n",
    "valid_losses_list = []\n",
    "valid_accs_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "training_mins_list = []\n",
    "training_secs_list = []\n",
    "test_iterator_list = []\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)\n",
    "\n",
    "for i in range(2):\n",
    "# for i in range(len(X_subjects)):\n",
    "    # Split data\n",
    "    train_iterator, valid_iterator, test_iterator = ShapePreparing(X_subjects[i], y_subjects[i], BATCH_SIZE=64)\n",
    "    \n",
    "    # Define model\n",
    "    model = CM_CW_CNN()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    # Training\n",
    "    if subjects[i]<10:\n",
    "        filename = \"CM_CW_CNN_0\"+str(subjects[i])\n",
    "    else:\n",
    "        filename = \"CM_CW_CNN_\"+str(subjects[i])\n",
    "    # filename = None\n",
    "    print(filename)\n",
    "    train_losses, valid_losses, train_accs, valid_accs, training_mins, training_secs = Training(model, train_iterator, valid_iterator, N_EPOCHS = 50, saveName=filename)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator, criterion)\n",
    "    # Record results\n",
    "    train_losses_list.append(train_losses); train_accs_list.append(train_accs)\n",
    "    valid_losses_list.append(valid_losses); valid_accs_list.append(valid_accs)\n",
    "    test_loss_list.append(test_loss); test_acc_list.append(test_acc)\n",
    "    training_mins_list.append(training_mins); training_secs_list.append(training_secs)\n",
    "    test_iterator_list.append(test_iterator)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses</th>\n",
       "      <th>valid_losses</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_accs</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>training_mins</th>\n",
       "      <th>training_secs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088903</td>\n",
       "      <td>2.78796</td>\n",
       "      <td>1.134824</td>\n",
       "      <td>97.859327</td>\n",
       "      <td>72.340426</td>\n",
       "      <td>89.212101</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114375</td>\n",
       "      <td>1.558639</td>\n",
       "      <td>0.979165</td>\n",
       "      <td>92.063492</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104392</td>\n",
       "      <td>3.138017</td>\n",
       "      <td>1.020948</td>\n",
       "      <td>95.049505</td>\n",
       "      <td>83.72093</td>\n",
       "      <td>89.880087</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.099433</td>\n",
       "      <td>0.973748</td>\n",
       "      <td>1.502679</td>\n",
       "      <td>96.69967</td>\n",
       "      <td>86.046512</td>\n",
       "      <td>87.936047</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073054</td>\n",
       "      <td>2.5534</td>\n",
       "      <td>0.664045</td>\n",
       "      <td>98.677249</td>\n",
       "      <td>87.037037</td>\n",
       "      <td>90.538194</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.161054</td>\n",
       "      <td>1.09075</td>\n",
       "      <td>0.943485</td>\n",
       "      <td>96.428571</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>86.024306</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100672</td>\n",
       "      <td>2.887216</td>\n",
       "      <td>1.13495</td>\n",
       "      <td>96.369637</td>\n",
       "      <td>79.069767</td>\n",
       "      <td>90.079942</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.554948</td>\n",
       "      <td>0.451361</td>\n",
       "      <td>0.751453</td>\n",
       "      <td>54.497354</td>\n",
       "      <td>90.740741</td>\n",
       "      <td>86.66088</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.080311</td>\n",
       "      <td>1.145841</td>\n",
       "      <td>0.292692</td>\n",
       "      <td>96.9163</td>\n",
       "      <td>84.375</td>\n",
       "      <td>87.596154</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.103188</td>\n",
       "      <td>2.002832</td>\n",
       "      <td>0.665496</td>\n",
       "      <td>94.223827</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.858386</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.099804</td>\n",
       "      <td>2.298008</td>\n",
       "      <td>1.793306</td>\n",
       "      <td>97.251908</td>\n",
       "      <td>82.895612</td>\n",
       "      <td>84.592246</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.099371</td>\n",
       "      <td>0.412378</td>\n",
       "      <td>1.336348</td>\n",
       "      <td>94.708995</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>89.293981</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.09768</td>\n",
       "      <td>1.067492</td>\n",
       "      <td>1.4608</td>\n",
       "      <td>97.51861</td>\n",
       "      <td>82.758621</td>\n",
       "      <td>80.713315</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.072774</td>\n",
       "      <td>1.387996</td>\n",
       "      <td>0.968995</td>\n",
       "      <td>97.619048</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>83.072917</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.102865</td>\n",
       "      <td>1.185871</td>\n",
       "      <td>0.902295</td>\n",
       "      <td>98.194946</td>\n",
       "      <td>82.5</td>\n",
       "      <td>88.202136</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.122811</td>\n",
       "      <td>1.27629</td>\n",
       "      <td>2.181206</td>\n",
       "      <td>96.037296</td>\n",
       "      <td>83.606557</td>\n",
       "      <td>82.428279</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.095899</td>\n",
       "      <td>3.979768</td>\n",
       "      <td>1.795199</td>\n",
       "      <td>98.019802</td>\n",
       "      <td>79.069767</td>\n",
       "      <td>90.279797</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.20219</td>\n",
       "      <td>2.031154</td>\n",
       "      <td>1.33804</td>\n",
       "      <td>82.539683</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>78.732639</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.093996</td>\n",
       "      <td>0.747425</td>\n",
       "      <td>1.427744</td>\n",
       "      <td>97.689769</td>\n",
       "      <td>93.023256</td>\n",
       "      <td>88.517442</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.087238</td>\n",
       "      <td>1.763253</td>\n",
       "      <td>1.540123</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>81.597222</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.10156</td>\n",
       "      <td>0.236789</td>\n",
       "      <td>1.796137</td>\n",
       "      <td>93.484419</td>\n",
       "      <td>92.0</td>\n",
       "      <td>82.781559</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.042787</td>\n",
       "      <td>1.72705</td>\n",
       "      <td>4.934751</td>\n",
       "      <td>98.583569</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.515161</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.170977</td>\n",
       "      <td>1.175583</td>\n",
       "      <td>1.671869</td>\n",
       "      <td>97.833935</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.202136</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.105302</td>\n",
       "      <td>1.86498</td>\n",
       "      <td>1.086267</td>\n",
       "      <td>97.022333</td>\n",
       "      <td>82.758621</td>\n",
       "      <td>91.311141</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.125987</td>\n",
       "      <td>0.283171</td>\n",
       "      <td>1.126844</td>\n",
       "      <td>98.015873</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>89.756944</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.080662</td>\n",
       "      <td>6.204941</td>\n",
       "      <td>2.036974</td>\n",
       "      <td>98.538622</td>\n",
       "      <td>85.615809</td>\n",
       "      <td>89.336223</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.028101</td>\n",
       "      <td>1.319952</td>\n",
       "      <td>1.456823</td>\n",
       "      <td>96.029777</td>\n",
       "      <td>87.931034</td>\n",
       "      <td>88.009511</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.40466</td>\n",
       "      <td>0.133116</td>\n",
       "      <td>0.202596</td>\n",
       "      <td>81.938326</td>\n",
       "      <td>90.625</td>\n",
       "      <td>86.045673</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.078049</td>\n",
       "      <td>3.677983</td>\n",
       "      <td>3.787814</td>\n",
       "      <td>96.984127</td>\n",
       "      <td>83.072917</td>\n",
       "      <td>83.917824</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.122276</td>\n",
       "      <td>1.717811</td>\n",
       "      <td>0.534406</td>\n",
       "      <td>96.825397</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>90.451389</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0433</td>\n",
       "      <td>1.092166</td>\n",
       "      <td>0.969764</td>\n",
       "      <td>95.767196</td>\n",
       "      <td>92.592593</td>\n",
       "      <td>83.680556</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.094955</td>\n",
       "      <td>0.46845</td>\n",
       "      <td>1.460253</td>\n",
       "      <td>94.189602</td>\n",
       "      <td>89.361702</td>\n",
       "      <td>82.114362</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.112403</td>\n",
       "      <td>0.652121</td>\n",
       "      <td>3.211607</td>\n",
       "      <td>96.622614</td>\n",
       "      <td>91.454575</td>\n",
       "      <td>81.040593</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.08481</td>\n",
       "      <td>1.552768</td>\n",
       "      <td>0.981229</td>\n",
       "      <td>97.111913</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.373813</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.066279</td>\n",
       "      <td>1.147051</td>\n",
       "      <td>0.562902</td>\n",
       "      <td>97.553517</td>\n",
       "      <td>91.489362</td>\n",
       "      <td>90.774601</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.077285</td>\n",
       "      <td>2.385688</td>\n",
       "      <td>1.964068</td>\n",
       "      <td>96.636086</td>\n",
       "      <td>78.723404</td>\n",
       "      <td>88.430851</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.099982</td>\n",
       "      <td>2.824264</td>\n",
       "      <td>2.882783</td>\n",
       "      <td>95.533499</td>\n",
       "      <td>72.413793</td>\n",
       "      <td>80.278533</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.052065</td>\n",
       "      <td>1.148133</td>\n",
       "      <td>1.192342</td>\n",
       "      <td>99.5338</td>\n",
       "      <td>93.442623</td>\n",
       "      <td>88.831967</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.207809</td>\n",
       "      <td>1.281801</td>\n",
       "      <td>1.480653</td>\n",
       "      <td>94.617564</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.485458</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.065116</td>\n",
       "      <td>3.96231</td>\n",
       "      <td>2.520943</td>\n",
       "      <td>98.014888</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>84.361413</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.090437</td>\n",
       "      <td>2.064956</td>\n",
       "      <td>2.195947</td>\n",
       "      <td>98.015873</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>88.28125</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_losses valid_losses test_loss train_accs  test_loss   test_acc  \\\n",
       "subjects                                                                        \n",
       "2            0.088903      2.78796  1.134824  97.859327  72.340426  89.212101   \n",
       "3            0.114375     1.558639  0.979165  92.063492  88.888889       87.5   \n",
       "4            0.104392     3.138017  1.020948  95.049505   83.72093  89.880087   \n",
       "5            0.099433     0.973748  1.502679   96.69967  86.046512  87.936047   \n",
       "6            0.073054       2.5534  0.664045  98.677249  87.037037  90.538194   \n",
       "7            0.161054      1.09075  0.943485  96.428571  88.888889  86.024306   \n",
       "8            0.100672     2.887216   1.13495  96.369637  79.069767  90.079942   \n",
       "9            0.554948     0.451361  0.751453  54.497354  90.740741   86.66088   \n",
       "10           0.080311     1.145841  0.292692    96.9163     84.375  87.596154   \n",
       "11           0.103188     2.002832  0.665496  94.223827       85.0  85.858386   \n",
       "12           0.099804     2.298008  1.793306  97.251908  82.895612  84.592246   \n",
       "13           0.099371     0.412378  1.336348  94.708995  94.444444  89.293981   \n",
       "14            0.09768     1.067492    1.4608   97.51861  82.758621  80.713315   \n",
       "15           0.072774     1.387996  0.968995  97.619048  86.111111  83.072917   \n",
       "16           0.102865     1.185871  0.902295  98.194946       82.5  88.202136   \n",
       "17           0.122811      1.27629  2.181206  96.037296  83.606557  82.428279   \n",
       "18           0.095899     3.979768  1.795199  98.019802  79.069767  90.279797   \n",
       "19            0.20219     2.031154   1.33804  82.539683  83.333333  78.732639   \n",
       "20           0.093996     0.747425  1.427744  97.689769  93.023256  88.517442   \n",
       "21           0.087238     1.763253  1.540123  97.222222  86.111111  81.597222   \n",
       "22            0.10156     0.236789  1.796137  93.484419       92.0  82.781559   \n",
       "23           0.042787      1.72705  4.934751  98.583569       88.0  80.515161   \n",
       "24           0.170977     1.175583  1.671869  97.833935       85.0  88.202136   \n",
       "25           0.105302      1.86498  1.086267  97.022333  82.758621  91.311141   \n",
       "26           0.125987     0.283171  1.126844  98.015873  94.444444  89.756944   \n",
       "28           0.080662     6.204941  2.036974  98.538622  85.615809  89.336223   \n",
       "29           0.028101     1.319952  1.456823  96.029777  87.931034  88.009511   \n",
       "30            0.40466     0.133116  0.202596  81.938326     90.625  86.045673   \n",
       "31           0.078049     3.677983  3.787814  96.984127  83.072917  83.917824   \n",
       "32           0.122276     1.717811  0.534406  96.825397  77.777778  90.451389   \n",
       "33             0.0433     1.092166  0.969764  95.767196  92.592593  83.680556   \n",
       "34           0.094955      0.46845  1.460253  94.189602  89.361702  82.114362   \n",
       "35           0.112403     0.652121  3.211607  96.622614  91.454575  81.040593   \n",
       "36            0.08481     1.552768  0.981229  97.111913       85.0  85.373813   \n",
       "37           0.066279     1.147051  0.562902  97.553517  91.489362  90.774601   \n",
       "38           0.077285     2.385688  1.964068  96.636086  78.723404  88.430851   \n",
       "39           0.099982     2.824264  2.882783  95.533499  72.413793  80.278533   \n",
       "40           0.052065     1.148133  1.192342    99.5338  93.442623  88.831967   \n",
       "41           0.207809     1.281801  1.480653  94.617564       80.0  83.485458   \n",
       "42           0.065116      3.96231  2.520943  98.014888  68.965517  84.361413   \n",
       "43           0.090437     2.064956  2.195947  98.015873  72.222222   88.28125   \n",
       "\n",
       "         training_mins training_secs  \n",
       "subjects                              \n",
       "2                    0             5  \n",
       "3                    0             3  \n",
       "4                    0             3  \n",
       "5                    0             3  \n",
       "6                    0             4  \n",
       "7                    0             2  \n",
       "8                    0             3  \n",
       "9                    0             4  \n",
       "10                   0             2  \n",
       "11                   0             3  \n",
       "12                   0             7  \n",
       "13                   0             4  \n",
       "14                   0             4  \n",
       "15                   0             2  \n",
       "16                   0             3  \n",
       "17                   0             4  \n",
       "18                   0             3  \n",
       "19                   0             5  \n",
       "20                   0             4  \n",
       "21                   0             3  \n",
       "22                   0             4  \n",
       "23                   0             4  \n",
       "24                   0             3  \n",
       "25                   0             4  \n",
       "26                   0             3  \n",
       "28                   0             6  \n",
       "29                   0             4  \n",
       "30                   0             2  \n",
       "31                   0             7  \n",
       "32                   0             2  \n",
       "33                   0             4  \n",
       "34                   0             4  \n",
       "35                   0             8  \n",
       "36                   0             3  \n",
       "37                   0             3  \n",
       "38                   0             3  \n",
       "39                   0             4  \n",
       "40                   0             5  \n",
       "41                   0             4  \n",
       "42                   0             4  \n",
       "43                   0             3  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"train_losses\", \"valid_losses\", \"test_loss\", \n",
    "    \"train_accs\", \"test_loss\", \"test_acc\", \n",
    "    \"training_mins\", \"training_secs\"]\n",
    "df = pd.DataFrame(columns=col, index=subjects)\n",
    "df.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    df.loc[subjects[i]] = [train_losses_list[i][-1], valid_losses_list[i][-1], test_loss_list[i], \n",
    "        train_accs_list[i][-1], valid_accs_list[i][-1], test_acc_list[i],\n",
    "        training_mins_list[i], training_secs_list[i]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results\\CM_CW_CNN\\CM_CW_CNN_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_losses      0.117311\n",
       "valid_losses      1.747817\n",
       "test_loss         1.509531\n",
       "train_accs       94.986345\n",
       "test_loss        84.947644\n",
       "test_acc         86.236513\n",
       "training_mins     0.000000\n",
       "training_secs     3.780488\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "81.83178191489361\n",
      "81.05053191489361\n",
      "[tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], device='cuda:0')]\n",
      "[tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
      "        2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), tensor([1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        2, 1, 1, 2, 1, 1], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "# model = CM_CW_CNN()\n",
    "model.load_state_dict(torch.load('results\\CM_CW_CNN\\CM_CW_CNN_02.pth.tar'))\n",
    "model.eval()\n",
    "# model = model.float()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print(len(test_iterator_list))\n",
    "test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[0], criterion)\n",
    "print(test_acc)\n",
    "print(test_acc_list[0])\n",
    "print(test_pred_label)\n",
    "print(test_true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cuda.is_available():\n",
    "#     net = model.cuda()\n",
    "#     X_test_tensor = X_test_tensor.cuda()\n",
    "# else:\n",
    "#     net = net.cpu()\n",
    "#     X_test_tensor = X_test_tensor.cpu()\n",
    "\n",
    "# output = net(X_test_tensor)\n",
    "# _, predicted = torch.max(output.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_losses, label=\"train\")\n",
    "# plt.plot(valid_losses, label=\"validation\")\n",
    "# plt.title(\"Losses\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_accs, label=\"train\")\n",
    "# plt.plot(valid_accs, label=\"validation\")\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
