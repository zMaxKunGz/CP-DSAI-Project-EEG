{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Brain Inverders Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braininvaders2015a.dataset import BrainInvaders2015a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainInvaders2015a()\n",
    "\n",
    "def loadData(subject, session = 'session_1', run = 'run_1'):\n",
    "    data = dataset._get_single_subject_data(subject)\n",
    "    data = data[session][run]\n",
    "    # data.set_montage(ten_twenty_montage)\n",
    "    return data\n",
    "\n",
    "data_subjects = []\n",
    "subjects = list(range(1,44))\n",
    "subjects.remove(1)\n",
    "subjects.remove(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_subjects.append(loadData(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import create_info\n",
    "from mne import Epochs, find_events\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def df_to_raw(df):\n",
    "    sfreq = 512\n",
    "    ch_names = list(df.columns)\n",
    "    ch_types = ['eeg'] * (len(df.columns) - 1) + ['stim']\n",
    "    ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "    df = df.T\n",
    "      #mne looks at the tranpose() format\n",
    "    df[:-1] *= 1e-6\n",
    "      #convert from uVolts to Volts (mne assumes Volts data)\n",
    "\n",
    "    info = create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n",
    "\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage(ten_twenty_montage)\n",
    "    return raw\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    \n",
    "    #reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "    #                       grad=4000e-13,    # 4000 fT/cm\n",
    "    #                       eeg=100e-6,       # 150 μV\n",
    "    #                       eog=250e-6)       # 250 μV\n",
    "\n",
    "    reject_criteria = dict(eeg=100e-6)  #most voltage in this range is not brain components\n",
    "\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs\n",
    "  \n",
    "def preprocessing(rawdata, runPCA=False):\n",
    "    # Convert and drop time column\n",
    "    data_ses1_run1_pd = rawdata.to_data_frame()\n",
    "    data_ses1_run1_pd = data_ses1_run1_pd.drop(['time'],axis = 1)\n",
    "    raw = df_to_raw(data_ses1_run1_pd)\n",
    "\n",
    "    # Notch Filter\n",
    "    raw.notch_filter(np.arange(50, 251, 50))\n",
    "\n",
    "    eeg_channels = mne.pick_types(raw.info, eeg=True)\n",
    "    raw.filter(1,24,method = 'iir')\n",
    "\n",
    "\n",
    "    if runPCA:\n",
    "      raw_df = raw.to_data_frame()\n",
    "      X1 = raw_df.drop(['time'],axis = 1)\n",
    "      X = X1.drop(['STI 014'],axis = 1)\n",
    "      y = raw_df['STI 014']\n",
    "      pca = PCA(n_components=32)\n",
    "      X = pca.fit(X.values).transform(X.values)\n",
    "      y1 = y.values.reshape(-1,1)\n",
    "      data = np.hstack((X,y1))\n",
    "      df = pd.DataFrame(data, columns = list(X1.columns))\n",
    "      raw = df_to_raw(df)\n",
    "\n",
    "    event_id = {'NonTarget': 1, 'Target': 2}\n",
    "    tmin = 0.0 #0\n",
    "    tmax = 1.0 #0.5 seconds\n",
    "    picks= eeg_channels\n",
    "    epochs = getEpochs(raw,event_id, tmin, tmax, picks)\n",
    "\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 24 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 24.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "360 events found\n",
      "Event IDs: [1 2]\n",
      "sample drop %:  0.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "X_subjects = []\n",
    "y_subjects = []\n",
    "\n",
    "for data in data_subjects:\n",
    "    X, y = preprocessing(data)    \n",
    "    X_subjects.append(X)\n",
    "    y_subjects.append(y)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshape, Convert to torch, Test/Train Split, and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "def ShapePreparing(X, y, BATCH_SIZE = 32):\n",
    "    X_reshaped = X[:, np.newaxis, :, :]\n",
    "    torch_X_reshaped = torch.from_numpy(X_reshaped)\n",
    "    torch_y = torch.from_numpy(y)\n",
    "\n",
    "    ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "    #Train test split\n",
    "    train_size = int(round(torch_X_reshaped.size()[0] * 0.7))\n",
    "    valid_size = int(round(torch_X_reshaped.size()[0] * 0.1))\n",
    "    test_size = int(round(torch_X_reshaped.size()[0] * 0.2))\n",
    "    sum_size = np.sum([train_size, valid_size, test_size])\n",
    "\n",
    "    while sum_size<torch_X_reshaped.shape[0]:\n",
    "        train_size += 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    while sum_size>torch_X_reshaped.shape[0]:\n",
    "        train_size -= 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "        \n",
    "    train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size])\n",
    "\n",
    "     \n",
    "    #Train set loader\n",
    "    train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    #Validation set loader\n",
    "    valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "\n",
    "    #Test set loader\n",
    "    test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = ShapePreparing(X, y, BATCH_SIZE=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 513])\n",
      "torch.Size([64, 1, 32, 513])\n",
      "torch.Size([64, 1, 32, 513])\n",
      "torch.Size([60, 1, 32, 513])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(train_iterator):\n",
    "    print(images.shape)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM-CW-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_CW_CNN(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, channels, height , width)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CM_CW_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,16,kernel_size=(32,1),stride=(1,1)))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16,16,kernel_size=(1,57),stride=(1,57)))\n",
    "        self.fc = nn.Sequential(nn.Linear(144,144),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(144,48),nn.ReLU(),nn.Dropout(0.75),\n",
    "                               nn.Linear(48,12),nn.ReLU(),nn.Dropout(0.75),\n",
    "                               nn.Linear(12,3),nn.ReLU(),nn.Dropout(0.05))\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        # print(\"X flatten\",x.shape)\n",
    "        # torch.manual_seed(9999)\n",
    "        x = self.fc(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda\n",
      "{'CM_CW_CNN'}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)\n",
    "\n",
    "model = CM_CW_CNN()\n",
    "model = model.float()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "print({type(model).__name__})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, print=False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "\n",
    "    trues = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "        \n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        if print:\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted)\n",
    "        predicteds.append(predicted)\n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        if print:\n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)\n",
    "        trues.append(labels)\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc, predicteds, trues\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)\n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "\n",
    "def Training(model, train_iterator, valid_iterator, N_EPOCHS = 50, saveName=None):\n",
    "\n",
    "    print(\"Trainning: subject\", subject)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    start_time_train = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label= evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            if saveName != None:\n",
    "                directory = 'results/CM_CW_CNN/'\n",
    "                fileName = saveName+'.pth.tar'\n",
    "                path = directory+fileName\n",
    "                while True:\n",
    "                    try:\n",
    "                        torch.save(model.state_dict(), path)\n",
    "                        # print(\"Model:{} saved.\".format(fileName))\n",
    "                        break\n",
    "                    except:\n",
    "                        os.mkdir(directory)\n",
    "                        open(path, 'w')\n",
    "    training_mins, training_secs = epoch_time(start_time_train, time.time())\n",
    "    return train_losses, valid_losses, train_accs, valid_accs, training_mins, training_secs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.338 | Train Acc: 88.89%\n",
      "\t Val. Loss: 0.592 |  Val. Acc: 88.89%\n"
     ]
    }
   ],
   "source": [
    "train_losses_list = []\n",
    "train_accs_list = []\n",
    "valid_losses_list = []\n",
    "valid_accs_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "training_mins_list = []\n",
    "training_secs_list = []\n",
    "\n",
    "for i in range(len(X_subjects)):\n",
    "    train_iterator, valid_iterator, test_iterator = ShapePreparing(X, y, BATCH_SIZE=64)\n",
    "    # Define model\n",
    "    model = CM_CW_CNN()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    # Training\n",
    "    if subjects[i]<10:\n",
    "        filename = \"CM_CW_CNN_0\"+str(subjects[i])\n",
    "    else:\n",
    "        filename = \"CM_CW_CNN_\"+str(subjects[i])\n",
    "    print(filename)\n",
    "    train_losses, valid_losses, train_accs, valid_accs, training_mins, training_secs = Training(model, train_iterator, valid_iterator, N_EPOCHS = 100, saveName=filename)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator, criterion)\n",
    "    # Record results\n",
    "    train_losses_list.append(train_losses); train_accs_list.append(train_accs)\n",
    "    valid_losses_list.append(valid_losses); valid_accs_list.append(valid_accs)\n",
    "    test_loss_list.append(test_loss); test_acc_list.append(test_acc)\n",
    "    training_mins_list.append(training_mins); training_secs_list.append(training_secs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses</th>\n",
       "      <th>valid_losses</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_accs</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>training_mins</th>\n",
       "      <th>training_secs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.495596</td>\n",
       "      <td>0.328979</td>\n",
       "      <td>0.57731</td>\n",
       "      <td>61.507937</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>85.243056</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375359</td>\n",
       "      <td>0.265955</td>\n",
       "      <td>0.288906</td>\n",
       "      <td>87.698413</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>89.670139</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.308437</td>\n",
       "      <td>1.939625</td>\n",
       "      <td>1.76292</td>\n",
       "      <td>90.47619</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>84.548611</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.309066</td>\n",
       "      <td>1.337006</td>\n",
       "      <td>0.431341</td>\n",
       "      <td>87.698413</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>94.097222</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.27011</td>\n",
       "      <td>0.419261</td>\n",
       "      <td>0.224111</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>91.927083</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.261754</td>\n",
       "      <td>0.825054</td>\n",
       "      <td>0.326146</td>\n",
       "      <td>84.920635</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>88.28125</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235042</td>\n",
       "      <td>0.214246</td>\n",
       "      <td>0.680876</td>\n",
       "      <td>87.698413</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>86.024306</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.31808</td>\n",
       "      <td>0.386093</td>\n",
       "      <td>0.465401</td>\n",
       "      <td>88.492063</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>92.621528</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.254915</td>\n",
       "      <td>1.015202</td>\n",
       "      <td>1.150784</td>\n",
       "      <td>89.68254</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>88.28125</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.281162</td>\n",
       "      <td>0.287966</td>\n",
       "      <td>0.101053</td>\n",
       "      <td>92.063492</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>95.572917</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.354461</td>\n",
       "      <td>0.863407</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>82.936508</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>90.451389</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.232767</td>\n",
       "      <td>1.08407</td>\n",
       "      <td>0.783504</td>\n",
       "      <td>84.52381</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>80.815972</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.345684</td>\n",
       "      <td>0.200139</td>\n",
       "      <td>1.688445</td>\n",
       "      <td>84.52381</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>94.184028</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.262018</td>\n",
       "      <td>2.363591</td>\n",
       "      <td>0.611934</td>\n",
       "      <td>93.253968</td>\n",
       "      <td>80.555556</td>\n",
       "      <td>85.329861</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.316578</td>\n",
       "      <td>0.778105</td>\n",
       "      <td>0.233524</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>94.878472</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.27838</td>\n",
       "      <td>0.086887</td>\n",
       "      <td>0.841716</td>\n",
       "      <td>86.904762</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>86.024306</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.300013</td>\n",
       "      <td>0.346724</td>\n",
       "      <td>1.019665</td>\n",
       "      <td>72.619048</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>88.28125</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.396843</td>\n",
       "      <td>0.308497</td>\n",
       "      <td>0.504127</td>\n",
       "      <td>86.507937</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>86.71875</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.275422</td>\n",
       "      <td>1.69554</td>\n",
       "      <td>1.419943</td>\n",
       "      <td>86.904762</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>88.28125</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.323353</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.603705</td>\n",
       "      <td>81.349206</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>88.975694</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.27706</td>\n",
       "      <td>0.539556</td>\n",
       "      <td>0.288228</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>94.097222</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.310582</td>\n",
       "      <td>1.109768</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>87.301587</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>94.097222</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.303409</td>\n",
       "      <td>0.965252</td>\n",
       "      <td>1.142616</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>91.927083</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.354295</td>\n",
       "      <td>0.18727</td>\n",
       "      <td>0.16153</td>\n",
       "      <td>87.698413</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>88.194444</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.315129</td>\n",
       "      <td>0.492387</td>\n",
       "      <td>0.314331</td>\n",
       "      <td>81.349206</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>90.451389</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.312064</td>\n",
       "      <td>0.142759</td>\n",
       "      <td>0.209815</td>\n",
       "      <td>84.126984</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>95.572917</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.27179</td>\n",
       "      <td>0.073916</td>\n",
       "      <td>1.507294</td>\n",
       "      <td>76.190476</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>91.927083</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.22733</td>\n",
       "      <td>0.833087</td>\n",
       "      <td>2.361792</td>\n",
       "      <td>83.730159</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>92.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.343921</td>\n",
       "      <td>0.162734</td>\n",
       "      <td>0.553428</td>\n",
       "      <td>80.555556</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>81.597222</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.307598</td>\n",
       "      <td>0.210309</td>\n",
       "      <td>0.316869</td>\n",
       "      <td>78.174603</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>80.902778</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.341072</td>\n",
       "      <td>0.29793</td>\n",
       "      <td>1.651962</td>\n",
       "      <td>63.888889</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.854167</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.298678</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.485036</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>89.756944</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.360138</td>\n",
       "      <td>0.041761</td>\n",
       "      <td>0.655759</td>\n",
       "      <td>85.31746</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.194444</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.306617</td>\n",
       "      <td>0.344074</td>\n",
       "      <td>0.575574</td>\n",
       "      <td>88.095238</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>91.927083</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.240677</td>\n",
       "      <td>0.118381</td>\n",
       "      <td>0.769981</td>\n",
       "      <td>79.365079</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>91.927083</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.236252</td>\n",
       "      <td>0.449903</td>\n",
       "      <td>0.601421</td>\n",
       "      <td>88.492063</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>82.378472</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.373455</td>\n",
       "      <td>0.584305</td>\n",
       "      <td>1.490213</td>\n",
       "      <td>86.904762</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>92.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.322761</td>\n",
       "      <td>2.436809</td>\n",
       "      <td>0.681537</td>\n",
       "      <td>90.47619</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>90.451389</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.310281</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.236918</td>\n",
       "      <td>81.349206</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>88.194444</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.275321</td>\n",
       "      <td>0.851428</td>\n",
       "      <td>0.335864</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>91.145833</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.338187</td>\n",
       "      <td>0.592194</td>\n",
       "      <td>0.22601</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>91.145833</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_losses valid_losses test_loss train_accs  test_loss   test_acc  \\\n",
       "subjects                                                                        \n",
       "2            0.495596     0.328979   0.57731  61.507937  94.444444  85.243056   \n",
       "3            0.375359     0.265955  0.288906  87.698413  94.444444  89.670139   \n",
       "4            0.308437     1.939625   1.76292   90.47619  83.333333  84.548611   \n",
       "5            0.309066     1.337006  0.431341  87.698413  86.111111  94.097222   \n",
       "6             0.27011     0.419261  0.224111  85.714286  88.888889  91.927083   \n",
       "7            0.261754     0.825054  0.326146  84.920635  88.888889   88.28125   \n",
       "8            0.235042     0.214246  0.680876  87.698413  94.444444  86.024306   \n",
       "9             0.31808     0.386093  0.465401  88.492063  88.888889  92.621528   \n",
       "10           0.254915     1.015202  1.150784   89.68254  91.666667   88.28125   \n",
       "11           0.281162     0.287966  0.101053  92.063492  94.444444  95.572917   \n",
       "12           0.354461     0.863407  0.698419  82.936508  86.111111  90.451389   \n",
       "13           0.232767      1.08407  0.783504   84.52381  91.666667  80.815972   \n",
       "14           0.345684     0.200139  1.688445   84.52381  94.444444  94.184028   \n",
       "15           0.262018     2.363591  0.611934  93.253968  80.555556  85.329861   \n",
       "16           0.316578     0.778105  0.233524  82.142857  86.111111  94.878472   \n",
       "17            0.27838     0.086887  0.841716  86.904762  97.222222  86.024306   \n",
       "18           0.300013     0.346724  1.019665  72.619048  94.444444   88.28125   \n",
       "19           0.396843     0.308497  0.504127  86.507937  91.666667   86.71875   \n",
       "20           0.275422      1.69554  1.419943  86.904762  88.888889   88.28125   \n",
       "21           0.323353       0.1132  0.603705  81.349206  97.222222  88.975694   \n",
       "22            0.27706     0.539556  0.288228  89.285714  88.888889  94.097222   \n",
       "23           0.310582     1.109768  0.312688  87.301587  88.888889  94.097222   \n",
       "24           0.303409     0.965252  1.142616  86.111111  83.333333  91.927083   \n",
       "25           0.354295      0.18727   0.16153  87.698413  94.444444  88.194444   \n",
       "26           0.315129     0.492387  0.314331  81.349206  91.666667  90.451389   \n",
       "28           0.312064     0.142759  0.209815  84.126984  94.444444  95.572917   \n",
       "29            0.27179     0.073916  1.507294  76.190476  97.222222  91.927083   \n",
       "30            0.22733     0.833087  2.361792  83.730159  91.666667  92.013889   \n",
       "31           0.343921     0.162734  0.553428  80.555556  86.111111  81.597222   \n",
       "32           0.307598     0.210309  0.316869  78.174603  88.888889  80.902778   \n",
       "33           0.341072      0.29793  1.651962  63.888889  83.333333  83.854167   \n",
       "34           0.298678     0.194331  0.485036  89.285714  97.222222  89.756944   \n",
       "35           0.360138     0.041761  0.655759   85.31746      100.0  88.194444   \n",
       "36           0.306617     0.344074  0.575574  88.095238  86.111111  91.927083   \n",
       "37           0.240677     0.118381  0.769981  79.365079  97.222222  91.927083   \n",
       "38           0.236252     0.449903  0.601421  88.492063  97.222222  82.378472   \n",
       "39           0.373455     0.584305  1.490213  86.904762  86.111111  92.013889   \n",
       "40           0.322761     2.436809  0.681537   90.47619  86.111111  90.451389   \n",
       "41           0.310281     0.719469  0.236918  81.349206  88.888889  88.194444   \n",
       "42           0.275321     0.851428  0.335864  82.142857  88.888889  91.145833   \n",
       "43           0.338187     0.592194   0.22601  88.888889  88.888889  91.145833   \n",
       "\n",
       "         training_mins training_secs  \n",
       "subjects                              \n",
       "2                    0            14  \n",
       "3                    0             5  \n",
       "4                    0             4  \n",
       "5                    0             4  \n",
       "6                    0             4  \n",
       "7                    0             4  \n",
       "8                    0             4  \n",
       "9                    0             4  \n",
       "10                   0             5  \n",
       "11                   0             5  \n",
       "12                   0             5  \n",
       "13                   0             5  \n",
       "14                   0             5  \n",
       "15                   0             5  \n",
       "16                   0             5  \n",
       "17                   0             5  \n",
       "18                   0             5  \n",
       "19                   0             4  \n",
       "20                   0             4  \n",
       "21                   0             4  \n",
       "22                   0             4  \n",
       "23                   0             4  \n",
       "24                   0             4  \n",
       "25                   0             4  \n",
       "26                   0             4  \n",
       "28                   0             4  \n",
       "29                   0             4  \n",
       "30                   0             4  \n",
       "31                   0             4  \n",
       "32                   0             4  \n",
       "33                   0             4  \n",
       "34                   0             4  \n",
       "35                   0             4  \n",
       "36                   0             4  \n",
       "37                   0             4  \n",
       "38                   0             4  \n",
       "39                   0             4  \n",
       "40                   0             4  \n",
       "41                   0             4  \n",
       "42                   0             4  \n",
       "43                   0             4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"train_losses\", \"valid_losses\", \"test_loss\", \n",
    "    \"train_accs\", \"test_loss\", \"test_acc\", \n",
    "    \"training_mins\", \"training_secs\"]\n",
    "df = pd.DataFrame(columns=col, index=subjects)\n",
    "df.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    df.loc[subjects[i]] = [train_losses_list[i][-1], valid_losses_list[i][-1], test_loss_list[i], \n",
    "        train_accs_list[i][-1], valid_accs_list[i][-1], test_acc_list[i],\n",
    "        training_mins_list[i], training_secs_list[i]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results\\CM_CW_CNN\\CM_CW_CNN_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_losses      0.307845\n",
       "valid_losses      0.639199\n",
       "test_loss         0.714456\n",
       "train_accs       84.301200\n",
       "test_loss        90.718157\n",
       "test_acc         89.316565\n",
       "training_mins     0.000000\n",
       "training_secs     4.487805\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_losses, label=\"train\")\n",
    "# plt.plot(valid_losses, label=\"validation\")\n",
    "# plt.title(\"Losses\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_accs, label=\"train\")\n",
    "# plt.plot(valid_accs, label=\"validation\")\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
