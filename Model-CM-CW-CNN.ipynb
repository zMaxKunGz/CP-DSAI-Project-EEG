{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Brain Inverders Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braininvaders2015a.dataset import BrainInvaders2015a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainInvaders2015a()\n",
    "\n",
    "def loadData(subject, session = 'session_1', run = 'run_1'):\n",
    "    data = dataset._get_single_subject_data(subject)\n",
    "    data = data[session][run]\n",
    "    # data.set_montage(ten_twenty_montage)\n",
    "    return data\n",
    "\n",
    "data_subjects = []\n",
    "subjects = list(range(1,44))\n",
    "subjects.remove(1)\n",
    "subjects.remove(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_subjects.append(loadData(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import create_info\n",
    "from mne import Epochs, find_events\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def df_to_raw(df):\n",
    "    sfreq = 512\n",
    "    ch_names = list(df.columns)\n",
    "    ch_types = ['eeg'] * (len(df.columns) - 1) + ['stim']\n",
    "    ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "    df = df.T\n",
    "      #mne looks at the tranpose() format\n",
    "    df[:-1] *= 1e-6\n",
    "      #convert from uVolts to Volts (mne assumes Volts data)\n",
    "\n",
    "    info = create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n",
    "\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage(ten_twenty_montage)\n",
    "    return raw\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    \n",
    "    #reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "    #                       grad=4000e-13,    # 4000 fT/cm\n",
    "    #                       eeg=100e-6,       # 150 μV\n",
    "    #                       eog=250e-6)       # 250 μV\n",
    "\n",
    "    reject_criteria = dict(eeg=100e-6)  #most voltage in this range is not brain components\n",
    "\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs\n",
    "  \n",
    "def preprocessing(rawdata, runPCA=False):\n",
    "    # Convert and drop time column\n",
    "    data_ses1_run1_pd = rawdata.to_data_frame()\n",
    "    data_ses1_run1_pd = data_ses1_run1_pd.drop(['time'],axis = 1)\n",
    "    raw = df_to_raw(data_ses1_run1_pd)\n",
    "\n",
    "    # Notch Filter\n",
    "    raw.notch_filter(np.arange(50, 251, 50))\n",
    "\n",
    "    eeg_channels = mne.pick_types(raw.info, eeg=True)\n",
    "      \n",
    "    raw.filter(1,24,method = 'iir')\n",
    "\n",
    "\n",
    "    if runPCA:\n",
    "      raw_df = raw.to_data_frame()\n",
    "      X1 = raw_df.drop(['time'],axis = 1)\n",
    "      X = X1.drop(['STI 014'],axis = 1)\n",
    "      y = raw_df['STI 014']\n",
    "      pca = PCA(n_components=32)\n",
    "      X = pca.fit(X.values).transform(X.values)\n",
    "      y1 = y.values.reshape(-1,1)\n",
    "      data = np.hstack((X,y1))\n",
    "      df = pd.DataFrame(data, columns = list(X1.columns))\n",
    "      raw = df_to_raw(df)\n",
    "\n",
    "    event_id = {'NonTarget': 1, 'Target': 2}\n",
    "    tmin = 0.0 #0\n",
    "    tmax = 1.0 #0.5 seconds\n",
    "    picks= eeg_channels\n",
    "    epochs = getEpochs(raw,event_id, tmin, tmax, picks)\n",
    "\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 24 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 24.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "360 events found\n",
      "Event IDs: [1 2]\n",
      "sample drop %:  0.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "X_subjects = []\n",
    "y_subjects = []\n",
    "runPCA = True\n",
    "\n",
    "for data in data_subjects:\n",
    "    X, y = preprocessing(data, runPCA=runPCA)    \n",
    "    X_subjects.append(X)\n",
    "    y_subjects.append(y)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshape, Convert to torch, Test/Train Split, and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "def ShapePreparing(X, y, BATCH_SIZE = 32):\n",
    "    X_reshaped = X[:, np.newaxis, :, :]\n",
    "    torch_X_reshaped = torch.from_numpy(X_reshaped)\n",
    "    torch_y = torch.from_numpy(y)\n",
    "\n",
    "    ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "    #Train test split\n",
    "    train_size = int(round(torch_X_reshaped.size()[0] * 0.7))\n",
    "    valid_size = int(round(torch_X_reshaped.size()[0] * 0.1))\n",
    "    test_size = int(round(torch_X_reshaped.size()[0] * 0.2))\n",
    "    sum_size = np.sum([train_size, valid_size, test_size])\n",
    "\n",
    "    # Adjust total size to equal to sample size\n",
    "    while sum_size<torch_X_reshaped.shape[0]:\n",
    "        train_size += 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    while sum_size>torch_X_reshaped.shape[0]:\n",
    "        train_size -= 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    \n",
    "    # Split data\n",
    "    train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size])\n",
    "\n",
    "    #Train set loader\n",
    "    train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    #Validation set loader\n",
    "    valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "\n",
    "    #Test set loader\n",
    "    test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                            batch_size=test_size, \n",
    "                                            shuffle=True)\n",
    "    return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM-CW-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_CW_CNN(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, channels, height , width)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CM_CW_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,16,kernel_size=(32,1),stride=(1,1)))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16,16,kernel_size=(1,57),stride=(1,57)))\n",
    "        self.fc = nn.Sequential(nn.Linear(144,144),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(144,48),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(48,12), nn.ReLU(), nn.Dropout(0.5),\n",
    "                               nn.Linear(12,3), nn.ReLU())\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        # print(\"X flatten\",x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, _print=False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "\n",
    "    trues = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "        \n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        if _print:\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted)\n",
    "        predicteds.append(predicted)\n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        if _print:\n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)\n",
    "        trues.append(labels)\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc, predicteds, trues\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)\n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def saveModel(saveName, model, type_='Best'):\n",
    "    directory = f'results/{type(model).__name__}/{type_}/'\n",
    "    fileName = f'{saveName}.pth.tar'\n",
    "    path = directory+fileName\n",
    "    while True:\n",
    "        try:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(\"Model:{} saved.\".format(fileName))\n",
    "            break\n",
    "        except:\n",
    "            os.makedirs(directory)\n",
    "            open(path, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "\n",
    "def Training(model, train_iterator, valid_iterator, N_EPOCHS = 50, saveName=None):\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    start_time_train = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label= evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Trainning:\", saveName)\n",
    "            print(f'Epoch: [{epoch+1:02}/{N_EPOCHS}]')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            if saveName != None:\n",
    "                saveModel(saveName, model, type_='Best')\n",
    "    if saveName != None:\n",
    "        saveModel(saveName, model, type_='Last')\n",
    "    training_time = time.time() - start_time_train\n",
    "    return train_losses, valid_losses, train_accs, valid_accs, training_time, best_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning: PCA_43\n",
      "Epoch: [100/100]\n",
      "\tTrain Loss: 0.062 | Train Acc: 96.83%\n",
      "\t Val. Loss: 2.393 |  Val. Acc: 86.11%\n",
      "Model:PCA_43.pth.tar saved.\n"
     ]
    }
   ],
   "source": [
    "train_losses_list = []\n",
    "train_accs_list = []\n",
    "valid_losses_list = []\n",
    "valid_accs_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "training_time_list = []\n",
    "best_epoch_list = []\n",
    "test_iterator_list = []\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)\n",
    "\n",
    "# for i in range(2):\n",
    "for i in range(len(X_subjects)):\n",
    "    # Split data\n",
    "    train_iterator, valid_iterator, test_iterator = ShapePreparing(X_subjects[i], y_subjects[i], BATCH_SIZE=64)\n",
    "    \n",
    "    # Define model\n",
    "    model = CM_CW_CNN()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    # Training\n",
    "    fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "    if subjects[i]<10:\n",
    "        filename = f'{fname}_0{str(subjects[i])}'\n",
    "    else:\n",
    "        filename = f'{fname}_{str(subjects[i])}'\n",
    "    # filename = None\n",
    "    print(filename)\n",
    "    train_losses, valid_losses, train_accs, valid_accs, training_time, best_epoch = Training(model, train_iterator, valid_iterator, N_EPOCHS = 100, saveName=filename)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator, criterion)\n",
    "    # Record results\n",
    "    train_losses_list.append(train_losses); train_accs_list.append(train_accs)\n",
    "    valid_losses_list.append(valid_losses); valid_accs_list.append(valid_accs)\n",
    "    test_loss_list.append(test_loss); test_acc_list.append(test_acc)\n",
    "    training_time_list.append(training_time); best_epoch_list.append(best_epoch)\n",
    "    test_iterator_list.append(test_iterator)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Best model ====\n",
      "max:  93.67088607594937\n",
      "min:  75.9493670886076\n",
      "mean:  85.1389657479522\n",
      "==== Last (Load) model ====\n",
      "max:  95.83333333333334\n",
      "min:  78.21782178217822\n",
      "mean:  86.71485830336462\n",
      "==== Last model ====\n",
      "max:  95.83333333333334\n",
      "min:  78.21782178217822\n",
      "mean:  86.71485830336462\n"
     ]
    }
   ],
   "source": [
    "def trainedModelLoader(path, device):\n",
    "    model = CM_CW_CNN()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    return model, criterion\n",
    "\n",
    "test_loss_best = []\n",
    "test_acc_best = []\n",
    "test_loss_last = []\n",
    "test_acc_last = []\n",
    "\n",
    "for i, subject in enumerate(subjects):\n",
    "    fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "    if subject<10:\n",
    "        filename = f'{fname}_0{str(subject)}'\n",
    "    else:\n",
    "        filename = f'{fname}_{str(subject)}'\n",
    "    # Best model\n",
    "    type_ = 'Best'\n",
    "    path = f'results/CM_CW_CNN/{type_}/{filename}.pth.tar'\n",
    "    model, criterion = trainedModelLoader(path, device)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[i], criterion)\n",
    "    test_loss_best.append(test_loss)\n",
    "    test_acc_best.append(test_acc)\n",
    "    # Last model\n",
    "    type_ = 'Last'\n",
    "    path = f'results/CM_CW_CNN/{type_}/{filename}.pth.tar'\n",
    "    model, criterion = trainedModelLoader(path, device)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[i], criterion)\n",
    "    test_loss_last.append(test_loss)\n",
    "    test_acc_last.append(test_acc)\n",
    "\n",
    "\n",
    "print(\"==== Best model ====\")\n",
    "# print(test_acc_best)\n",
    "print(\"max: \", np.max(test_acc_best))\n",
    "print(\"min: \", np.min(test_acc_best))\n",
    "print(\"mean: \", np.mean(test_acc_best))\n",
    "\n",
    "print(\"==== Last (Load) model ====\")\n",
    "# print(test_acc_list)\n",
    "print(\"max: \", np.max(test_acc_last))\n",
    "print(\"min: \", np.min(test_acc_last))\n",
    "print(\"mean: \", np.mean(test_acc_last))\n",
    "\n",
    "print(\"==== Last model ====\")\n",
    "# print(test_acc_list)\n",
    "print(\"max: \", np.max(test_acc_list))\n",
    "print(\"min: \", np.min(test_acc_list))\n",
    "print(\"mean: \", np.mean(test_acc_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses_last</th>\n",
       "      <th>train_accs_last</th>\n",
       "      <th>valid_losses_last</th>\n",
       "      <th>valid_accs_last</th>\n",
       "      <th>train_losses_best</th>\n",
       "      <th>train_accs_best</th>\n",
       "      <th>valid_losses_best</th>\n",
       "      <th>valid_accs_best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033477</td>\n",
       "      <td>98.470948</td>\n",
       "      <td>3.380852</td>\n",
       "      <td>89.361702</td>\n",
       "      <td>0.659266</td>\n",
       "      <td>85.321101</td>\n",
       "      <td>0.588148</td>\n",
       "      <td>82.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039144</td>\n",
       "      <td>98.015873</td>\n",
       "      <td>1.862289</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.555932</td>\n",
       "      <td>81.349206</td>\n",
       "      <td>0.476741</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054083</td>\n",
       "      <td>98.679868</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>0.045363</td>\n",
       "      <td>97.689769</td>\n",
       "      <td>0.154441</td>\n",
       "      <td>97.674419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056015</td>\n",
       "      <td>99.339934</td>\n",
       "      <td>1.214027</td>\n",
       "      <td>90.697674</td>\n",
       "      <td>0.558403</td>\n",
       "      <td>80.19802</td>\n",
       "      <td>0.470323</td>\n",
       "      <td>83.72093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086726</td>\n",
       "      <td>98.412698</td>\n",
       "      <td>0.813562</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.195103</td>\n",
       "      <td>91.534392</td>\n",
       "      <td>0.181639</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.058245</td>\n",
       "      <td>97.619048</td>\n",
       "      <td>2.901345</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.626383</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.762713</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.048715</td>\n",
       "      <td>99.339934</td>\n",
       "      <td>1.53699</td>\n",
       "      <td>88.372093</td>\n",
       "      <td>0.397812</td>\n",
       "      <td>89.438944</td>\n",
       "      <td>0.350337</td>\n",
       "      <td>88.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.082021</td>\n",
       "      <td>98.941799</td>\n",
       "      <td>0.868622</td>\n",
       "      <td>92.592593</td>\n",
       "      <td>0.076023</td>\n",
       "      <td>98.148148</td>\n",
       "      <td>0.319412</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.043827</td>\n",
       "      <td>97.356828</td>\n",
       "      <td>2.86374</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.49138</td>\n",
       "      <td>82.819383</td>\n",
       "      <td>0.567445</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.028948</td>\n",
       "      <td>97.472924</td>\n",
       "      <td>2.257622</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.422375</td>\n",
       "      <td>82.67148</td>\n",
       "      <td>0.582147</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.037871</td>\n",
       "      <td>98.778626</td>\n",
       "      <td>4.624156</td>\n",
       "      <td>86.835106</td>\n",
       "      <td>0.518352</td>\n",
       "      <td>82.59542</td>\n",
       "      <td>0.416782</td>\n",
       "      <td>86.585771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.041558</td>\n",
       "      <td>97.089947</td>\n",
       "      <td>1.095757</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>89.417989</td>\n",
       "      <td>0.250867</td>\n",
       "      <td>92.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.133557</td>\n",
       "      <td>88.833747</td>\n",
       "      <td>2.469579</td>\n",
       "      <td>82.758621</td>\n",
       "      <td>0.458024</td>\n",
       "      <td>73.200993</td>\n",
       "      <td>0.51285</td>\n",
       "      <td>86.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.151994</td>\n",
       "      <td>92.460317</td>\n",
       "      <td>1.054559</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.584492</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.340012</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.014238</td>\n",
       "      <td>97.472924</td>\n",
       "      <td>3.97565</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0.433068</td>\n",
       "      <td>84.115523</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.023147</td>\n",
       "      <td>98.601399</td>\n",
       "      <td>2.706109</td>\n",
       "      <td>81.967213</td>\n",
       "      <td>0.33701</td>\n",
       "      <td>83.449883</td>\n",
       "      <td>0.475815</td>\n",
       "      <td>81.967213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.076375</td>\n",
       "      <td>99.669967</td>\n",
       "      <td>1.528786</td>\n",
       "      <td>83.72093</td>\n",
       "      <td>0.516412</td>\n",
       "      <td>80.858086</td>\n",
       "      <td>0.311141</td>\n",
       "      <td>90.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.029828</td>\n",
       "      <td>98.941799</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.19487</td>\n",
       "      <td>92.328042</td>\n",
       "      <td>0.138183</td>\n",
       "      <td>92.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.031644</td>\n",
       "      <td>96.039604</td>\n",
       "      <td>2.464793</td>\n",
       "      <td>83.72093</td>\n",
       "      <td>0.201851</td>\n",
       "      <td>91.419142</td>\n",
       "      <td>0.667343</td>\n",
       "      <td>81.395349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.036093</td>\n",
       "      <td>98.809524</td>\n",
       "      <td>2.179591</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.513397</td>\n",
       "      <td>83.730159</td>\n",
       "      <td>0.793334</td>\n",
       "      <td>72.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.030287</td>\n",
       "      <td>97.450425</td>\n",
       "      <td>2.099636</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.361783</td>\n",
       "      <td>83.852691</td>\n",
       "      <td>0.407448</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.019291</td>\n",
       "      <td>99.150142</td>\n",
       "      <td>1.820383</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.469264</td>\n",
       "      <td>85.552408</td>\n",
       "      <td>0.506904</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.042811</td>\n",
       "      <td>97.111913</td>\n",
       "      <td>0.785036</td>\n",
       "      <td>92.5</td>\n",
       "      <td>0.17311</td>\n",
       "      <td>93.140794</td>\n",
       "      <td>0.244899</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.146259</td>\n",
       "      <td>89.081886</td>\n",
       "      <td>1.013656</td>\n",
       "      <td>87.931034</td>\n",
       "      <td>0.34329</td>\n",
       "      <td>87.841191</td>\n",
       "      <td>0.211716</td>\n",
       "      <td>93.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.020305</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.869137</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.326481</td>\n",
       "      <td>86.507937</td>\n",
       "      <td>0.576982</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.014123</td>\n",
       "      <td>99.582463</td>\n",
       "      <td>7.124968</td>\n",
       "      <td>81.847426</td>\n",
       "      <td>0.296892</td>\n",
       "      <td>89.770355</td>\n",
       "      <td>0.321844</td>\n",
       "      <td>80.284926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.028806</td>\n",
       "      <td>97.51861</td>\n",
       "      <td>2.515975</td>\n",
       "      <td>81.034483</td>\n",
       "      <td>0.687556</td>\n",
       "      <td>71.46402</td>\n",
       "      <td>0.517364</td>\n",
       "      <td>86.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.066064</td>\n",
       "      <td>94.273128</td>\n",
       "      <td>0.994615</td>\n",
       "      <td>93.75</td>\n",
       "      <td>0.262881</td>\n",
       "      <td>88.105727</td>\n",
       "      <td>0.410339</td>\n",
       "      <td>90.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.025394</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>6.862159</td>\n",
       "      <td>76.614583</td>\n",
       "      <td>0.553248</td>\n",
       "      <td>81.587302</td>\n",
       "      <td>0.374141</td>\n",
       "      <td>84.184028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.058144</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>4.615644</td>\n",
       "      <td>80.555556</td>\n",
       "      <td>0.495838</td>\n",
       "      <td>84.126984</td>\n",
       "      <td>0.705729</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.083792</td>\n",
       "      <td>99.73545</td>\n",
       "      <td>1.491929</td>\n",
       "      <td>90.740741</td>\n",
       "      <td>0.308404</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>0.379105</td>\n",
       "      <td>90.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.048556</td>\n",
       "      <td>97.859327</td>\n",
       "      <td>4.170544</td>\n",
       "      <td>87.234043</td>\n",
       "      <td>0.846713</td>\n",
       "      <td>63.914373</td>\n",
       "      <td>0.734429</td>\n",
       "      <td>76.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.072345</td>\n",
       "      <td>99.559471</td>\n",
       "      <td>0.412668</td>\n",
       "      <td>91.704253</td>\n",
       "      <td>0.342068</td>\n",
       "      <td>87.958884</td>\n",
       "      <td>0.230563</td>\n",
       "      <td>91.188789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.086422</td>\n",
       "      <td>99.638989</td>\n",
       "      <td>1.341197</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.48739</td>\n",
       "      <td>85.559567</td>\n",
       "      <td>0.374716</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.025863</td>\n",
       "      <td>99.388379</td>\n",
       "      <td>0.611582</td>\n",
       "      <td>89.361702</td>\n",
       "      <td>0.102054</td>\n",
       "      <td>92.04893</td>\n",
       "      <td>0.182862</td>\n",
       "      <td>91.489362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.060207</td>\n",
       "      <td>97.859327</td>\n",
       "      <td>1.361408</td>\n",
       "      <td>89.361702</td>\n",
       "      <td>0.551025</td>\n",
       "      <td>79.204893</td>\n",
       "      <td>0.35567</td>\n",
       "      <td>87.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.031464</td>\n",
       "      <td>99.255583</td>\n",
       "      <td>2.024432</td>\n",
       "      <td>89.655172</td>\n",
       "      <td>0.232446</td>\n",
       "      <td>92.555831</td>\n",
       "      <td>0.322507</td>\n",
       "      <td>86.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.041504</td>\n",
       "      <td>99.7669</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>91.803279</td>\n",
       "      <td>0.225191</td>\n",
       "      <td>89.51049</td>\n",
       "      <td>0.384404</td>\n",
       "      <td>85.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.082627</td>\n",
       "      <td>98.583569</td>\n",
       "      <td>4.22147</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.546203</td>\n",
       "      <td>77.620397</td>\n",
       "      <td>0.549635</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.109813</td>\n",
       "      <td>98.014888</td>\n",
       "      <td>2.208062</td>\n",
       "      <td>87.931034</td>\n",
       "      <td>0.686581</td>\n",
       "      <td>78.908189</td>\n",
       "      <td>0.50164</td>\n",
       "      <td>86.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.061926</td>\n",
       "      <td>96.825397</td>\n",
       "      <td>2.392774</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>0.604605</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>0.62899</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_losses_last train_accs_last valid_losses_last valid_accs_last  \\\n",
       "subjects                                                                       \n",
       "2                 0.033477       98.470948          3.380852       89.361702   \n",
       "3                 0.039144       98.015873          1.862289       91.666667   \n",
       "4                 0.054083       98.679868          0.237275       95.348837   \n",
       "5                 0.056015       99.339934          1.214027       90.697674   \n",
       "6                 0.086726       98.412698          0.813562       94.444444   \n",
       "7                 0.058245       97.619048          2.901345       91.666667   \n",
       "8                 0.048715       99.339934           1.53699       88.372093   \n",
       "9                 0.082021       98.941799          0.868622       92.592593   \n",
       "10                0.043827       97.356828           2.86374            87.5   \n",
       "11                0.028948       97.472924          2.257622            80.0   \n",
       "12                0.037871       98.778626          4.624156       86.835106   \n",
       "13                0.041558       97.089947          1.095757       94.444444   \n",
       "14                0.133557       88.833747          2.469579       82.758621   \n",
       "15                0.151994       92.460317          1.054559       91.666667   \n",
       "16                0.014238       97.472924           3.97565            77.5   \n",
       "17                0.023147       98.601399          2.706109       81.967213   \n",
       "18                0.076375       99.669967          1.528786        83.72093   \n",
       "19                0.029828       98.941799          0.858824       88.888889   \n",
       "20                0.031644       96.039604          2.464793        83.72093   \n",
       "21                0.036093       98.809524          2.179591       77.777778   \n",
       "22                0.030287       97.450425          2.099636            92.0   \n",
       "23                0.019291       99.150142          1.820383            90.0   \n",
       "24                0.042811       97.111913          0.785036            92.5   \n",
       "25                0.146259       89.081886          1.013656       87.931034   \n",
       "26                0.020305           100.0          1.869137       88.888889   \n",
       "28                0.014123       99.582463          7.124968       81.847426   \n",
       "29                0.028806        97.51861          2.515975       81.034483   \n",
       "30                0.066064       94.273128          0.994615           93.75   \n",
       "31                0.025394       99.206349          6.862159       76.614583   \n",
       "32                0.058144       99.206349          4.615644       80.555556   \n",
       "33                0.083792        99.73545          1.491929       90.740741   \n",
       "34                0.048556       97.859327          4.170544       87.234043   \n",
       "35                0.072345       99.559471          0.412668       91.704253   \n",
       "36                0.086422       99.638989          1.341197            85.0   \n",
       "37                0.025863       99.388379          0.611582       89.361702   \n",
       "38                0.060207       97.859327          1.361408       89.361702   \n",
       "39                0.031464       99.255583          2.024432       89.655172   \n",
       "40                0.041504         99.7669          0.584458       91.803279   \n",
       "41                0.082627       98.583569           4.22147            84.0   \n",
       "42                0.109813       98.014888          2.208062       87.931034   \n",
       "43                0.061926       96.825397          2.392774       86.111111   \n",
       "\n",
       "         train_losses_best train_accs_best valid_losses_best valid_accs_best  \n",
       "subjects                                                                      \n",
       "2                 0.659266       85.321101          0.588148       82.978723  \n",
       "3                 0.555932       81.349206          0.476741       83.333333  \n",
       "4                 0.045363       97.689769          0.154441       97.674419  \n",
       "5                 0.558403        80.19802          0.470323        83.72093  \n",
       "6                 0.195103       91.534392          0.181639       94.444444  \n",
       "7                 0.626383            75.0          0.762713            75.0  \n",
       "8                 0.397812       89.438944          0.350337       88.372093  \n",
       "9                 0.076023       98.148148          0.319412       96.296296  \n",
       "10                 0.49138       82.819383          0.567445           81.25  \n",
       "11                0.422375        82.67148          0.582147            80.0  \n",
       "12                0.518352        82.59542          0.416782       86.585771  \n",
       "13                  0.3278       89.417989          0.250867       92.592593  \n",
       "14                0.458024       73.200993           0.51285       86.206897  \n",
       "15                0.584492       77.777778          0.340012       91.666667  \n",
       "16                0.433068       84.115523          0.622832            80.0  \n",
       "17                 0.33701       83.449883          0.475815       81.967213  \n",
       "18                0.516412       80.858086          0.311141       90.697674  \n",
       "19                 0.19487       92.328042          0.138183       92.592593  \n",
       "20                0.201851       91.419142          0.667343       81.395349  \n",
       "21                0.513397       83.730159          0.793334       72.222222  \n",
       "22                0.361783       83.852691          0.407448            88.0  \n",
       "23                0.469264       85.552408          0.506904            84.0  \n",
       "24                 0.17311       93.140794          0.244899            95.0  \n",
       "25                 0.34329       87.841191          0.211716       93.103448  \n",
       "26                0.326481       86.507937          0.576982       88.888889  \n",
       "28                0.296892       89.770355          0.321844       80.284926  \n",
       "29                0.687556        71.46402          0.517364       86.206897  \n",
       "30                0.262881       88.105727          0.410339          90.625  \n",
       "31                0.553248       81.587302          0.374141       84.184028  \n",
       "32                0.495838       84.126984          0.705729            75.0  \n",
       "33                0.308404       92.857143          0.379105       90.740741  \n",
       "34                0.846713       63.914373          0.734429       76.595745  \n",
       "35                0.342068       87.958884          0.230563       91.188789  \n",
       "36                 0.48739       85.559567          0.374716            90.0  \n",
       "37                0.102054        92.04893          0.182862       91.489362  \n",
       "38                0.551025       79.204893           0.35567       87.234043  \n",
       "39                0.232446       92.555831          0.322507       86.206897  \n",
       "40                0.225191        89.51049          0.384404       85.245902  \n",
       "41                0.546203       77.620397          0.549635            86.0  \n",
       "42                0.686581       78.908189           0.50164       86.206897  \n",
       "43                0.604605       78.571429           0.62899       77.777778  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"train_losses_last\", \"train_accs_last\", \"valid_losses_last\", \"valid_accs_last\", \n",
    "    \"train_losses_best\", \"train_accs_best\", \"valid_losses_best\", \"valid_accs_best\"]\n",
    "train_result = pd.DataFrame(columns=col, index=subjects)\n",
    "train_result.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    b = best_epoch_list[i]\n",
    "    train_result.loc[subjects[i]] = [\n",
    "        train_losses_list[i][-1], train_accs_list[i][-1], \n",
    "        valid_losses_list[i][-1], valid_accs_list[i][-1],\n",
    "        train_losses_list[i][b], train_accs_list[i][b], \n",
    "        valid_losses_list[i][b], valid_accs_list[i][b],\n",
    "    ]\n",
    "\n",
    "fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "path = f'results\\CM_CW_CNN\\{fname}_Train_result.csv'\n",
    "train_result.to_csv(path)\n",
    "print(\"Training Results\")\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses_last</th>\n",
       "      <th>train_accs_last</th>\n",
       "      <th>valid_losses_last</th>\n",
       "      <th>valid_accs_last</th>\n",
       "      <th>train_losses_best</th>\n",
       "      <th>train_accs_best</th>\n",
       "      <th>valid_losses_best</th>\n",
       "      <th>valid_accs_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.014123</td>\n",
       "      <td>88.833747</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>76.614583</td>\n",
       "      <td>0.045363</td>\n",
       "      <td>63.914373</td>\n",
       "      <td>0.138183</td>\n",
       "      <td>72.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.151994</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.124968</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>0.846713</td>\n",
       "      <td>98.148148</td>\n",
       "      <td>0.793334</td>\n",
       "      <td>97.674419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.055208</td>\n",
       "      <td>97.790640</td>\n",
       "      <td>2.229655</td>\n",
       "      <td>87.535519</td>\n",
       "      <td>0.415033</td>\n",
       "      <td>84.724951</td>\n",
       "      <td>0.436692</td>\n",
       "      <td>86.170160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_losses_last  train_accs_last  valid_losses_last  valid_accs_last  \\\n",
       "min            0.014123        88.833747           0.237275        76.614583   \n",
       "max            0.151994       100.000000           7.124968        95.348837   \n",
       "mean           0.055208        97.790640           2.229655        87.535519   \n",
       "\n",
       "      train_losses_best  train_accs_best  valid_losses_best  valid_accs_best  \n",
       "min            0.045363        63.914373           0.138183        72.222222  \n",
       "max            0.846713        98.148148           0.793334        97.674419  \n",
       "mean           0.415033        84.724951           0.436692        86.170160  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dfDescript(x):\n",
    "    return pd.DataFrame(index=['min','max', 'mean'], data=[x.min(), x.max(), x.mean()])\n",
    "\n",
    "dfDescript(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.851064</td>\n",
       "      <td>84.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>95.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.697674</td>\n",
       "      <td>88.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.372093</td>\n",
       "      <td>86.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86.111111</td>\n",
       "      <td>84.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.023256</td>\n",
       "      <td>87.209302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>87.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84.615385</td>\n",
       "      <td>89.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.949367</td>\n",
       "      <td>83.544304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.818182</td>\n",
       "      <td>86.096257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90.740741</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.73913</td>\n",
       "      <td>81.73913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84.722222</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>82.278481</td>\n",
       "      <td>88.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>82.786885</td>\n",
       "      <td>83.606557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>82.55814</td>\n",
       "      <td>89.534884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85.185185</td>\n",
       "      <td>87.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90.697674</td>\n",
       "      <td>91.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>90.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>78.217822</td>\n",
       "      <td>78.217822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>85.148515</td>\n",
       "      <td>86.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>89.873418</td>\n",
       "      <td>91.139241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>89.565217</td>\n",
       "      <td>92.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>84.722222</td>\n",
       "      <td>90.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78.832117</td>\n",
       "      <td>81.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>87.826087</td>\n",
       "      <td>93.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>90.769231</td>\n",
       "      <td>89.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>79.444444</td>\n",
       "      <td>82.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>86.111111</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>87.037037</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>85.106383</td>\n",
       "      <td>87.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>86.597938</td>\n",
       "      <td>87.628866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>93.670886</td>\n",
       "      <td>92.405063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>87.234043</td>\n",
       "      <td>84.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>76.595745</td>\n",
       "      <td>79.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>82.608696</td>\n",
       "      <td>79.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>83.606557</td>\n",
       "      <td>82.786885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>84.158416</td>\n",
       "      <td>80.19802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>80.869565</td>\n",
       "      <td>80.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>86.111111</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         best_model_acc last_model_acc\n",
       "subjects                              \n",
       "2             80.851064      84.042553\n",
       "3             88.888889      95.833333\n",
       "4             90.697674      88.372093\n",
       "5             88.372093      86.046512\n",
       "6             83.333333      83.333333\n",
       "7             86.111111      84.722222\n",
       "8             93.023256      87.209302\n",
       "9             88.888889      87.962963\n",
       "10            84.615385      89.230769\n",
       "11            75.949367      83.544304\n",
       "12            81.818182      86.096257\n",
       "13            90.740741      91.666667\n",
       "14             81.73913       81.73913\n",
       "15            84.722222      86.111111\n",
       "16            82.278481      88.607595\n",
       "17            82.786885      83.606557\n",
       "18             82.55814      89.534884\n",
       "19            85.185185      87.962963\n",
       "20            90.697674      91.860465\n",
       "21            83.333333      90.277778\n",
       "22            78.217822      78.217822\n",
       "23            85.148515      86.138614\n",
       "24            89.873418      91.139241\n",
       "25            89.565217      92.173913\n",
       "26            84.722222      90.277778\n",
       "28            78.832117      81.021898\n",
       "29            87.826087      93.043478\n",
       "30            90.769231      89.230769\n",
       "31            79.444444      82.777778\n",
       "32            86.111111      88.888889\n",
       "33            87.037037      88.888889\n",
       "34            85.106383      87.234043\n",
       "35            86.597938      87.628866\n",
       "36            93.670886      92.405063\n",
       "37            87.234043      84.042553\n",
       "38            76.595745      79.787234\n",
       "39            82.608696      79.130435\n",
       "40            83.606557      82.786885\n",
       "41            84.158416       80.19802\n",
       "42            80.869565      80.869565\n",
       "43            86.111111      91.666667"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"best_model_acc\", \"last_model_acc\"]\n",
    "Test_result = pd.DataFrame(columns=col, index=subjects)\n",
    "Test_result.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    Test_result.loc[subjects[i]] = [test_acc_best[i], test_acc_last[i]]\n",
    "\n",
    "fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "path = f'results\\CM_CW_CNN\\{fname}_Test_result.csv'\n",
    "Test_result.to_csv(path)\n",
    "print(\"Test Results\")\n",
    "Test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with PCA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75.949367</td>\n",
       "      <td>78.217822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.670886</td>\n",
       "      <td>95.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.138966</td>\n",
       "      <td>86.714858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_model_acc  last_model_acc\n",
       "min        75.949367       78.217822\n",
       "max        93.670886       95.833333\n",
       "mean       85.138966       86.714858"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"with PCA\")\n",
    "dfDescript(Test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outwith PCA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>73.611111</td>\n",
       "      <td>73.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>93.055556</td>\n",
       "      <td>93.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.390244</td>\n",
       "      <td>84.371770</td>\n",
       "      <td>85.834738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subjects  best_model_acc  last_model_acc\n",
       "min    2.000000       73.611111       73.611111\n",
       "max   43.000000       93.055556       93.055556\n",
       "mean  22.390244       84.371770       85.834738"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"outwith PCA\")\n",
    "path = f'results\\CM_CW_CNN\\woPCA_Test_result.csv'\n",
    "Test_result_woPCA = pd.read_csv(path)\n",
    "dfDescript(Test_result_woPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23213816cd0>]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_losses, label=\"train\")\n",
    "# plt.plot(valid_losses, label=\"validation\")\n",
    "# plt.title(\"Losses\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_accs, label=\"train\")\n",
    "# plt.plot(valid_accs, label=\"validation\")\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
