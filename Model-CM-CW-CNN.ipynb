{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Brain Inverders Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braininvaders2015a.dataset import BrainInvaders2015a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainInvaders2015a()\n",
    "\n",
    "def loadData(subject, session = 'session_1', run = 'run_1'):\n",
    "    data = dataset._get_single_subject_data(subject)\n",
    "    data = data[session][run]\n",
    "    # data.set_montage(ten_twenty_montage)\n",
    "    return data\n",
    "\n",
    "data_subjects = []\n",
    "subjects = list(range(1,44))\n",
    "subjects.remove(1)\n",
    "subjects.remove(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_subjects.append(loadData(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import create_info\n",
    "from mne import Epochs, find_events\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def df_to_raw(df):\n",
    "    sfreq = 512\n",
    "    ch_names = list(df.columns)\n",
    "    ch_types = ['eeg'] * (len(df.columns) - 1) + ['stim']\n",
    "    ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "    df = df.T\n",
    "      #mne looks at the tranpose() format\n",
    "    df[:-1] *= 1e-6\n",
    "      #convert from uVolts to Volts (mne assumes Volts data)\n",
    "\n",
    "    info = create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n",
    "\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage(ten_twenty_montage)\n",
    "    return raw\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    \n",
    "    #reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "    #                       grad=4000e-13,    # 4000 fT/cm\n",
    "    #                       eeg=100e-6,       # 150 μV\n",
    "    #                       eog=250e-6)       # 250 μV\n",
    "\n",
    "    reject_criteria = dict(eeg=100e-6)  #most voltage in this range is not brain components\n",
    "\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs\n",
    "  \n",
    "def preprocessing(rawdata, runPCA=False):\n",
    "    # Convert and drop time column\n",
    "    data_ses1_run1_pd = rawdata.to_data_frame()\n",
    "    data_ses1_run1_pd = data_ses1_run1_pd.drop(['time'],axis = 1)\n",
    "    raw = df_to_raw(data_ses1_run1_pd)\n",
    "\n",
    "    # Notch Filter\n",
    "    raw.notch_filter(np.arange(50, 251, 50))\n",
    "\n",
    "    eeg_channels = mne.pick_types(raw.info, eeg=True)\n",
    "      \n",
    "    raw.filter(1,24,method = 'iir')\n",
    "\n",
    "\n",
    "    if runPCA:\n",
    "      raw_df = raw.to_data_frame()\n",
    "      X1 = raw_df.drop(['time'],axis = 1)\n",
    "      X = X1.drop(['STI 014'],axis = 1)\n",
    "      y = raw_df['STI 014']\n",
    "      pca = PCA(n_components=32)\n",
    "      X = pca.fit(X.values).transform(X.values)\n",
    "      y1 = y.values.reshape(-1,1)\n",
    "      data = np.hstack((X,y1))\n",
    "      df = pd.DataFrame(data, columns = list(X1.columns))\n",
    "      raw = df_to_raw(df)\n",
    "\n",
    "    event_id = {'NonTarget': 1, 'Target': 2}\n",
    "    tmin = 0.0 #0\n",
    "    tmax = 1.0 #0.5 seconds\n",
    "    picks= eeg_channels\n",
    "    epochs = getEpochs(raw,event_id, tmin, tmax, picks)\n",
    "\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 24 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 24.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "360 events found\n",
      "Event IDs: [1 2]\n",
      "sample drop %:  0.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "X_subjects = []\n",
    "y_subjects = []\n",
    "runPCA = True\n",
    "\n",
    "for data in data_subjects:\n",
    "    X, y = preprocessing(data, runPCA=runPCA)    \n",
    "    X_subjects.append(X)\n",
    "    y_subjects.append(y)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshape, Convert to torch, Test/Train Split, and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "def ShapePreparing(X, y, BATCH_SIZE = 32):\n",
    "    X_reshaped = X[:, np.newaxis, :, :]\n",
    "    torch_X_reshaped = torch.from_numpy(X_reshaped)\n",
    "    torch_y = torch.from_numpy(y)\n",
    "\n",
    "    ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "    #Train test split\n",
    "    train_size = int(round(torch_X_reshaped.size()[0] * 0.7))\n",
    "    valid_size = int(round(torch_X_reshaped.size()[0] * 0.1))\n",
    "    test_size = int(round(torch_X_reshaped.size()[0] * 0.2))\n",
    "    sum_size = np.sum([train_size, valid_size, test_size])\n",
    "\n",
    "    # Adjust total size to equal to sample size\n",
    "    while sum_size<torch_X_reshaped.shape[0]:\n",
    "        train_size += 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    while sum_size>torch_X_reshaped.shape[0]:\n",
    "        train_size -= 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    \n",
    "    # Split data\n",
    "    train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size])\n",
    "\n",
    "    #Train set loader\n",
    "    train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    #Validation set loader\n",
    "    valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "\n",
    "    #Test set loader\n",
    "    test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                            batch_size=test_size, \n",
    "                                            shuffle=True)\n",
    "    return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM-CW-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_CW_CNN(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, channels, height , width)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CM_CW_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,16,kernel_size=(32,1),stride=(1,1)))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16,16,kernel_size=(1,57),stride=(1,57)))\n",
    "        self.fc = nn.Sequential(nn.Linear(144,144),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(144,24),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(24,3),\n",
    "                               nn.ReLU(),\n",
    "                            #    nn.Dropout(0.5),\n",
    "                            #    nn.Linear(12,3), nn.ReLU()\n",
    "                               )\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        # print(\"X flatten\",x.shape)\n",
    "        # torch.manual_seed(9999)\n",
    "        x = self.fc(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, _print=False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "\n",
    "    trues = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "        \n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        if _print:\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted)\n",
    "        predicteds.append(predicted)\n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        if _print:\n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)\n",
    "        trues.append(labels)\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc, predicteds, trues\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)\n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def saveModel(saveName, model, type_='Best'):\n",
    "    directory = f'results/{type(model).__name__}/{type_}/'\n",
    "    fileName = f'{saveName}.pth.tar'\n",
    "    path = directory+fileName\n",
    "    while True:\n",
    "        try:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(\"Model:{} saved.\".format(fileName))\n",
    "            break\n",
    "        except:\n",
    "            os.makedirs(directory)\n",
    "            open(path, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "\n",
    "def Training(model, train_iterator, valid_iterator, N_EPOCHS = 50, saveName=None):\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    start_time_train = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label= evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Trainning:\", saveName)\n",
    "            print(f'Epoch: [{epoch+1:02}/{N_EPOCHS}]')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            if saveName != None:\n",
    "                saveModel(saveName, model, type_='Best')\n",
    "    if saveName != None:\n",
    "        saveModel(saveName, model, type_='Last')\n",
    "    training_time = time.time() - start_time_train\n",
    "    return train_losses, valid_losses, train_accs, valid_accs, training_time, best_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning: PCA_43\n",
      "Epoch: [100/100]\n",
      "\tTrain Loss: 0.008 | Train Acc: 100.00%\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 94.44%\n",
      "Model:PCA_43.pth.tar saved.\n"
     ]
    }
   ],
   "source": [
    "train_losses_list = []\n",
    "train_accs_list = []\n",
    "valid_losses_list = []\n",
    "valid_accs_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "training_time_list = []\n",
    "best_epoch_list = []\n",
    "test_iterator_list = []\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)\n",
    "\n",
    "# for i in range(2):\n",
    "for i in range(len(X_subjects)):\n",
    "    # Split data\n",
    "    train_iterator, valid_iterator, test_iterator = ShapePreparing(X_subjects[i], y_subjects[i], BATCH_SIZE=64)\n",
    "    \n",
    "    # Define model\n",
    "    model = CM_CW_CNN()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    # Training\n",
    "    fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "    if subjects[i]<10:\n",
    "        filename = f'{fname}_0{str(subjects[i])}'\n",
    "    else:\n",
    "        filename = f'{fname}_{str(subjects[i])}'\n",
    "    # filename = None\n",
    "    print(filename)\n",
    "    train_losses, valid_losses, train_accs, valid_accs, training_time, best_epoch = Training(model, train_iterator, valid_iterator, N_EPOCHS = 100, saveName=filename)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator, criterion)\n",
    "    # Record results\n",
    "    train_losses_list.append(train_losses); train_accs_list.append(train_accs)\n",
    "    valid_losses_list.append(valid_losses); valid_accs_list.append(valid_accs)\n",
    "    test_loss_list.append(test_loss); test_acc_list.append(test_acc)\n",
    "    training_time_list.append(training_time); best_epoch_list.append(best_epoch)\n",
    "    test_iterator_list.append(test_iterator)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Best model ====\n",
      "max:  94.44444444444444\n",
      "min:  49.504950495049506\n",
      "mean:  83.41921812103506\n",
      "==== Last (Load) model ====\n",
      "max:  95.34883720930233\n",
      "min:  80.8695652173913\n",
      "mean:  87.13653172345026\n",
      "==== Last model ====\n",
      "max:  95.34883720930233\n",
      "min:  80.8695652173913\n",
      "mean:  87.13653172345026\n"
     ]
    }
   ],
   "source": [
    "def trainedModelLoader(path, device):\n",
    "    model = CM_CW_CNN()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    return model, criterion\n",
    "\n",
    "test_loss_best = []\n",
    "test_acc_best = []\n",
    "test_loss_last = []\n",
    "test_acc_last = []\n",
    "\n",
    "for i, subject in enumerate(subjects):\n",
    "    fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "    if subject<10:\n",
    "        filename = f'{fname}_0{str(subject)}'\n",
    "    else:\n",
    "        filename = f'{fname}_{str(subject)}'\n",
    "    # Best model\n",
    "    type_ = 'Best'\n",
    "    path = f'results/CM_CW_CNN/{type_}/{filename}.pth.tar'\n",
    "    model, criterion = trainedModelLoader(path, device)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[i], criterion)\n",
    "    test_loss_best.append(test_loss)\n",
    "    test_acc_best.append(test_acc)\n",
    "    # Last model\n",
    "    type_ = 'Last'\n",
    "    path = f'results/CM_CW_CNN/{type_}/{filename}.pth.tar'\n",
    "    model, criterion = trainedModelLoader(path, device)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[i], criterion)\n",
    "    test_loss_last.append(test_loss)\n",
    "    test_acc_last.append(test_acc)\n",
    "\n",
    "\n",
    "print(\"==== Best model ====\")\n",
    "# print(test_acc_best)\n",
    "print(\"max: \", np.max(test_acc_best))\n",
    "print(\"min: \", np.min(test_acc_best))\n",
    "print(\"mean: \", np.mean(test_acc_best))\n",
    "\n",
    "print(\"==== Last (Load) model ====\")\n",
    "# print(test_acc_list)\n",
    "print(\"max: \", np.max(test_acc_last))\n",
    "print(\"min: \", np.min(test_acc_last))\n",
    "print(\"mean: \", np.mean(test_acc_last))\n",
    "\n",
    "print(\"==== Last model ====\")\n",
    "# print(test_acc_list)\n",
    "print(\"max: \", np.max(test_acc_list))\n",
    "print(\"min: \", np.min(test_acc_list))\n",
    "print(\"mean: \", np.mean(test_acc_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses_last</th>\n",
       "      <th>train_accs_last</th>\n",
       "      <th>valid_losses_last</th>\n",
       "      <th>valid_accs_last</th>\n",
       "      <th>train_losses_best</th>\n",
       "      <th>train_accs_best</th>\n",
       "      <th>valid_losses_best</th>\n",
       "      <th>valid_accs_best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036898</td>\n",
       "      <td>99.69419</td>\n",
       "      <td>2.812117</td>\n",
       "      <td>78.723404</td>\n",
       "      <td>0.382584</td>\n",
       "      <td>85.015291</td>\n",
       "      <td>0.498455</td>\n",
       "      <td>89.361702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012335</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.697673</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.160659</td>\n",
       "      <td>92.460317</td>\n",
       "      <td>0.331342</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009349</td>\n",
       "      <td>99.669967</td>\n",
       "      <td>0.30002</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>0.09436</td>\n",
       "      <td>96.69967</td>\n",
       "      <td>0.067262</td>\n",
       "      <td>97.674419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003736</td>\n",
       "      <td>99.669967</td>\n",
       "      <td>1.38886</td>\n",
       "      <td>90.697674</td>\n",
       "      <td>0.18774</td>\n",
       "      <td>93.729373</td>\n",
       "      <td>0.412712</td>\n",
       "      <td>83.72093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>99.73545</td>\n",
       "      <td>1.133647</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.397962</td>\n",
       "      <td>83.597884</td>\n",
       "      <td>0.354826</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006961</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.716776</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.384073</td>\n",
       "      <td>84.920635</td>\n",
       "      <td>0.755963</td>\n",
       "      <td>69.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010536</td>\n",
       "      <td>99.669967</td>\n",
       "      <td>1.894707</td>\n",
       "      <td>88.372093</td>\n",
       "      <td>0.338782</td>\n",
       "      <td>85.478548</td>\n",
       "      <td>0.416485</td>\n",
       "      <td>90.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013956</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.923618</td>\n",
       "      <td>90.740741</td>\n",
       "      <td>0.268998</td>\n",
       "      <td>93.650794</td>\n",
       "      <td>0.228985</td>\n",
       "      <td>90.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010582</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.444403</td>\n",
       "      <td>96.875</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>98.678414</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>96.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.019655</td>\n",
       "      <td>99.638989</td>\n",
       "      <td>1.939882</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.510428</td>\n",
       "      <td>83.032491</td>\n",
       "      <td>0.52601</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.026051</td>\n",
       "      <td>99.847328</td>\n",
       "      <td>3.745333</td>\n",
       "      <td>88.148271</td>\n",
       "      <td>0.292958</td>\n",
       "      <td>87.175573</td>\n",
       "      <td>0.391814</td>\n",
       "      <td>85.272606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007578</td>\n",
       "      <td>99.73545</td>\n",
       "      <td>1.096308</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.183254</td>\n",
       "      <td>91.534392</td>\n",
       "      <td>0.356471</td>\n",
       "      <td>85.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006647</td>\n",
       "      <td>99.751861</td>\n",
       "      <td>10.473317</td>\n",
       "      <td>79.310345</td>\n",
       "      <td>1.076771</td>\n",
       "      <td>31.761787</td>\n",
       "      <td>0.969906</td>\n",
       "      <td>62.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002165</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005289</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.089739</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.235269</td>\n",
       "      <td>89.891697</td>\n",
       "      <td>0.473748</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.015469</td>\n",
       "      <td>99.7669</td>\n",
       "      <td>0.973289</td>\n",
       "      <td>88.52459</td>\n",
       "      <td>0.366279</td>\n",
       "      <td>86.247086</td>\n",
       "      <td>0.296496</td>\n",
       "      <td>93.442623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.075516</td>\n",
       "      <td>99.339934</td>\n",
       "      <td>1.625545</td>\n",
       "      <td>83.72093</td>\n",
       "      <td>0.112218</td>\n",
       "      <td>95.379538</td>\n",
       "      <td>0.371391</td>\n",
       "      <td>93.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028232</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>1.675074</td>\n",
       "      <td>87.037037</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>85.978836</td>\n",
       "      <td>0.324311</td>\n",
       "      <td>90.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003847</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.595556</td>\n",
       "      <td>79.069767</td>\n",
       "      <td>0.194993</td>\n",
       "      <td>94.389439</td>\n",
       "      <td>0.646166</td>\n",
       "      <td>81.395349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010264</td>\n",
       "      <td>98.809524</td>\n",
       "      <td>1.314774</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.354294</td>\n",
       "      <td>87.301587</td>\n",
       "      <td>0.248458</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.02402</td>\n",
       "      <td>99.716714</td>\n",
       "      <td>1.076374</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.103141</td>\n",
       "      <td>97.167139</td>\n",
       "      <td>0.20602</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004089</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.806612</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.852894</td>\n",
       "      <td>69.405099</td>\n",
       "      <td>0.672672</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005705</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.988459</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>90.613718</td>\n",
       "      <td>0.222988</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.022726</td>\n",
       "      <td>99.503722</td>\n",
       "      <td>0.616793</td>\n",
       "      <td>93.103448</td>\n",
       "      <td>0.094531</td>\n",
       "      <td>95.28536</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>94.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.004686</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.276833</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.086438</td>\n",
       "      <td>98.412698</td>\n",
       "      <td>0.342049</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.00935</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.915519</td>\n",
       "      <td>81.066176</td>\n",
       "      <td>0.355185</td>\n",
       "      <td>85.803758</td>\n",
       "      <td>0.289703</td>\n",
       "      <td>78.768382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001103</td>\n",
       "      <td>99.503722</td>\n",
       "      <td>2.564159</td>\n",
       "      <td>87.931034</td>\n",
       "      <td>0.424408</td>\n",
       "      <td>83.622829</td>\n",
       "      <td>0.422778</td>\n",
       "      <td>81.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.016222</td>\n",
       "      <td>99.118943</td>\n",
       "      <td>0.942484</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.368084</td>\n",
       "      <td>85.462555</td>\n",
       "      <td>0.44054</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.002514</td>\n",
       "      <td>99.84127</td>\n",
       "      <td>2.805971</td>\n",
       "      <td>82.517361</td>\n",
       "      <td>0.592151</td>\n",
       "      <td>83.809524</td>\n",
       "      <td>0.505242</td>\n",
       "      <td>83.072917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.006979</td>\n",
       "      <td>99.603175</td>\n",
       "      <td>1.7246</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.280263</td>\n",
       "      <td>88.492063</td>\n",
       "      <td>0.262234</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.00119</td>\n",
       "      <td>99.73545</td>\n",
       "      <td>2.451602</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.316057</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>0.389098</td>\n",
       "      <td>87.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.008698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.276657</td>\n",
       "      <td>97.87234</td>\n",
       "      <td>0.055138</td>\n",
       "      <td>96.636086</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>95.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.025024</td>\n",
       "      <td>99.853157</td>\n",
       "      <td>0.661893</td>\n",
       "      <td>91.970039</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>87.958884</td>\n",
       "      <td>0.210856</td>\n",
       "      <td>89.626289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001194</td>\n",
       "      <td>99.638989</td>\n",
       "      <td>0.626344</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>98.916968</td>\n",
       "      <td>0.18432</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.018628</td>\n",
       "      <td>99.388379</td>\n",
       "      <td>1.170931</td>\n",
       "      <td>82.978723</td>\n",
       "      <td>0.05729</td>\n",
       "      <td>96.330275</td>\n",
       "      <td>0.504441</td>\n",
       "      <td>82.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.00789</td>\n",
       "      <td>99.69419</td>\n",
       "      <td>2.629918</td>\n",
       "      <td>82.978723</td>\n",
       "      <td>0.536648</td>\n",
       "      <td>83.792049</td>\n",
       "      <td>0.482477</td>\n",
       "      <td>85.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.009869</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.501193</td>\n",
       "      <td>77.586207</td>\n",
       "      <td>0.410933</td>\n",
       "      <td>87.096774</td>\n",
       "      <td>0.658383</td>\n",
       "      <td>84.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.004543</td>\n",
       "      <td>99.7669</td>\n",
       "      <td>1.637013</td>\n",
       "      <td>85.245902</td>\n",
       "      <td>0.733221</td>\n",
       "      <td>74.825175</td>\n",
       "      <td>0.609182</td>\n",
       "      <td>81.967213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.004046</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.666153</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.210376</td>\n",
       "      <td>26.912181</td>\n",
       "      <td>1.033606</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.021232</td>\n",
       "      <td>99.751861</td>\n",
       "      <td>2.565455</td>\n",
       "      <td>81.034483</td>\n",
       "      <td>0.426165</td>\n",
       "      <td>83.126551</td>\n",
       "      <td>0.435969</td>\n",
       "      <td>86.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.008038</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.406777</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>0.225136</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_losses_last train_accs_last valid_losses_last valid_accs_last  \\\n",
       "subjects                                                                       \n",
       "2                 0.036898        99.69419          2.812117       78.723404   \n",
       "3                 0.012335           100.0          0.697673       91.666667   \n",
       "4                 0.009349       99.669967           0.30002       95.348837   \n",
       "5                 0.003736       99.669967           1.38886       90.697674   \n",
       "6                 0.010108        99.73545          1.133647       88.888889   \n",
       "7                 0.006961           100.0          2.716776       83.333333   \n",
       "8                 0.010536       99.669967          1.894707       88.372093   \n",
       "9                 0.013956           100.0          0.923618       90.740741   \n",
       "10                0.010582           100.0          0.444403          96.875   \n",
       "11                0.019655       99.638989          1.939882            82.5   \n",
       "12                0.026051       99.847328          3.745333       88.148271   \n",
       "13                0.007578        99.73545          1.096308       88.888889   \n",
       "14                0.006647       99.751861         10.473317       79.310345   \n",
       "15                0.002165       99.206349          0.000172           100.0   \n",
       "16                0.005289           100.0          1.089739            87.5   \n",
       "17                0.015469         99.7669          0.973289        88.52459   \n",
       "18                0.075516       99.339934          1.625545        83.72093   \n",
       "19                0.028232       99.206349          1.675074       87.037037   \n",
       "20                0.003847           100.0          2.595556       79.069767   \n",
       "21                0.010264       98.809524          1.314774       91.666667   \n",
       "22                 0.02402       99.716714          1.076374            90.0   \n",
       "23                0.004089           100.0          4.806612            78.0   \n",
       "24                0.005705           100.0          0.988459            90.0   \n",
       "25                0.022726       99.503722          0.616793       93.103448   \n",
       "26                0.004686           100.0          1.276833       91.666667   \n",
       "28                 0.00935           100.0          6.915519       81.066176   \n",
       "29                0.001103       99.503722          2.564159       87.931034   \n",
       "30                0.016222       99.118943          0.942484            87.5   \n",
       "31                0.002514        99.84127          2.805971       82.517361   \n",
       "32                0.006979       99.603175            1.7246       88.888889   \n",
       "33                 0.00119        99.73545          2.451602       83.333333   \n",
       "34                0.008698           100.0          0.276657        97.87234   \n",
       "35                0.025024       99.853157          0.661893       91.970039   \n",
       "36                0.001194       99.638989          0.626344            90.0   \n",
       "37                0.018628       99.388379          1.170931       82.978723   \n",
       "38                 0.00789        99.69419          2.629918       82.978723   \n",
       "39                0.009869           100.0          3.501193       77.586207   \n",
       "40                0.004543         99.7669          1.637013       85.245902   \n",
       "41                0.004046           100.0          4.666153            82.0   \n",
       "42                0.021232       99.751861          2.565455       81.034483   \n",
       "43                0.008038           100.0          0.406777       94.444444   \n",
       "\n",
       "         train_losses_best train_accs_best valid_losses_best valid_accs_best  \n",
       "subjects                                                                      \n",
       "2                 0.382584       85.015291          0.498455       89.361702  \n",
       "3                 0.160659       92.460317          0.331342       86.111111  \n",
       "4                  0.09436        96.69967          0.067262       97.674419  \n",
       "5                  0.18774       93.729373          0.412712        83.72093  \n",
       "6                 0.397962       83.597884          0.354826       88.888889  \n",
       "7                 0.384073       84.920635          0.755963       69.444444  \n",
       "8                 0.338782       85.478548          0.416485       90.697674  \n",
       "9                 0.268998       93.650794          0.228985       90.740741  \n",
       "10                0.017275       98.678414          0.049274          96.875  \n",
       "11                0.510428       83.032491           0.52601            82.5  \n",
       "12                0.292958       87.175573          0.391814       85.272606  \n",
       "13                0.183254       91.534392          0.356471       85.185185  \n",
       "14                1.076771       31.761787          0.969906       62.068966  \n",
       "15                0.002165       99.206349          0.000172           100.0  \n",
       "16                0.235269       89.891697          0.473748            80.0  \n",
       "17                0.366279       86.247086          0.296496       93.442623  \n",
       "18                0.112218       95.379538          0.371391       93.023256  \n",
       "19                0.403102       85.978836          0.324311       90.740741  \n",
       "20                0.194993       94.389439          0.646166       81.395349  \n",
       "21                0.354294       87.301587          0.248458       88.888889  \n",
       "22                0.103141       97.167139           0.20602            90.0  \n",
       "23                0.852894       69.405099          0.672672            78.0  \n",
       "24                0.304033       90.613718          0.222988            90.0  \n",
       "25                0.094531        95.28536            0.1651       94.827586  \n",
       "26                0.086438       98.412698          0.342049       94.444444  \n",
       "28                0.355185       85.803758          0.289703       78.768382  \n",
       "29                0.424408       83.622829          0.422778       81.034483  \n",
       "30                0.368084       85.462555           0.44054           81.25  \n",
       "31                0.592151       83.809524          0.505242       83.072917  \n",
       "32                0.280263       88.492063          0.262234       88.888889  \n",
       "33                0.316057       85.714286          0.389098       87.037037  \n",
       "34                0.055138       96.636086          0.054454       95.744681  \n",
       "35                0.299949       87.958884          0.210856       89.626289  \n",
       "36                0.013007       98.916968           0.18432            92.5  \n",
       "37                 0.05729       96.330275          0.504441       82.978723  \n",
       "38                0.536648       83.792049          0.482477       85.106383  \n",
       "39                0.410933       87.096774          0.658383       84.482759  \n",
       "40                0.733221       74.825175          0.609182       81.967213  \n",
       "41                1.210376       26.912181          1.033606            40.0  \n",
       "42                0.426165       83.126551          0.435969       86.206897  \n",
       "43                0.006507       99.206349          0.225136       97.222222  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"train_losses_last\", \"train_accs_last\", \"valid_losses_last\", \"valid_accs_last\", \n",
    "    \"train_losses_best\", \"train_accs_best\", \"valid_losses_best\", \"valid_accs_best\"]\n",
    "train_result = pd.DataFrame(columns=col, index=subjects)\n",
    "train_result.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    b = best_epoch_list[i]\n",
    "    train_result.loc[subjects[i]] = [\n",
    "        train_losses_list[i][-1], train_accs_list[i][-1], \n",
    "        valid_losses_list[i][-1], valid_accs_list[i][-1],\n",
    "        train_losses_list[i][b], train_accs_list[i][b], \n",
    "        valid_losses_list[i][b], valid_accs_list[i][b],\n",
    "    ]\n",
    "\n",
    "fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "path = f'results\\CM_CW_CNN\\{fname}_Train_result.csv'\n",
    "train_result.to_csv(path)\n",
    "print(\"Training Results\")\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses_last</th>\n",
       "      <th>train_accs_last</th>\n",
       "      <th>valid_losses_last</th>\n",
       "      <th>valid_accs_last</th>\n",
       "      <th>train_losses_best</th>\n",
       "      <th>train_accs_best</th>\n",
       "      <th>valid_losses_best</th>\n",
       "      <th>valid_accs_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001103</td>\n",
       "      <td>98.809524</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>77.586207</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>26.912181</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.075516</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.473317</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.210376</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>1.033606</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012754</td>\n",
       "      <td>99.728261</td>\n",
       "      <td>2.028111</td>\n",
       "      <td>87.344656</td>\n",
       "      <td>0.329039</td>\n",
       "      <td>86.456586</td>\n",
       "      <td>0.391158</td>\n",
       "      <td>85.833937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_losses_last  train_accs_last  valid_losses_last  valid_accs_last  \\\n",
       "min            0.001103        98.809524           0.000172        77.586207   \n",
       "max            0.075516       100.000000          10.473317       100.000000   \n",
       "mean           0.012754        99.728261           2.028111        87.344656   \n",
       "\n",
       "      train_losses_best  train_accs_best  valid_losses_best  valid_accs_best  \n",
       "min            0.002165        26.912181           0.000172        40.000000  \n",
       "max            1.210376        99.206349           1.033606       100.000000  \n",
       "mean           0.329039        86.456586           0.391158        85.833937  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dfDescript(x):\n",
    "    return pd.DataFrame(index=['min','max', 'mean'], data=[x.min(), x.max(), x.mean()])\n",
    "\n",
    "dfDescript(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.659574</td>\n",
       "      <td>81.914894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.444444</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.023256</td>\n",
       "      <td>95.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.883721</td>\n",
       "      <td>86.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84.259259</td>\n",
       "      <td>90.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.944444</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.55814</td>\n",
       "      <td>91.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>87.037037</td>\n",
       "      <td>87.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90.769231</td>\n",
       "      <td>89.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83.544304</td>\n",
       "      <td>87.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.213904</td>\n",
       "      <td>85.561497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82.407407</td>\n",
       "      <td>89.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62.608696</td>\n",
       "      <td>88.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>91.666667</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>82.278481</td>\n",
       "      <td>82.278481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>85.245902</td>\n",
       "      <td>86.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81.395349</td>\n",
       "      <td>84.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87.962963</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>88.372093</td>\n",
       "      <td>86.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>84.722222</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>87.128713</td>\n",
       "      <td>85.148515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>83.168317</td>\n",
       "      <td>91.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>86.075949</td>\n",
       "      <td>82.278481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>87.826087</td>\n",
       "      <td>86.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>81.944444</td>\n",
       "      <td>90.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>81.751825</td>\n",
       "      <td>83.941606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>81.73913</td>\n",
       "      <td>86.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>80.0</td>\n",
       "      <td>83.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>78.888889</td>\n",
       "      <td>82.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>84.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>87.962963</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>90.425532</td>\n",
       "      <td>93.617021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>80.927835</td>\n",
       "      <td>83.505155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>83.544304</td>\n",
       "      <td>83.544304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>85.106383</td>\n",
       "      <td>87.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>78.723404</td>\n",
       "      <td>88.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>85.217391</td>\n",
       "      <td>87.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>84.42623</td>\n",
       "      <td>88.52459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>49.50495</td>\n",
       "      <td>82.178218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>85.217391</td>\n",
       "      <td>80.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>90.277778</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         best_model_acc last_model_acc\n",
       "subjects                              \n",
       "2             77.659574      81.914894\n",
       "3             94.444444      94.444444\n",
       "4             93.023256      95.348837\n",
       "5             84.883721      86.046512\n",
       "6             84.259259      90.740741\n",
       "7             81.944444      88.888889\n",
       "8              82.55814      91.860465\n",
       "9             87.037037      87.037037\n",
       "10            90.769231      89.230769\n",
       "11            83.544304      87.341772\n",
       "12            80.213904      85.561497\n",
       "13            82.407407      89.814815\n",
       "14            62.608696      88.695652\n",
       "15            91.666667      91.666667\n",
       "16            82.278481      82.278481\n",
       "17            85.245902      86.065574\n",
       "18            81.395349      84.883721\n",
       "19            87.962963      86.111111\n",
       "20            88.372093      86.046512\n",
       "21            84.722222      88.888889\n",
       "22            87.128713      85.148515\n",
       "23            83.168317      91.089109\n",
       "24            86.075949      82.278481\n",
       "25            87.826087      86.086957\n",
       "26            81.944444      90.277778\n",
       "28            81.751825      83.941606\n",
       "29             81.73913      86.956522\n",
       "30                 80.0      83.076923\n",
       "31            78.888889      82.777778\n",
       "32            83.333333      84.722222\n",
       "33            87.962963      86.111111\n",
       "34            90.425532      93.617021\n",
       "35            80.927835      83.505155\n",
       "36            83.544304      83.544304\n",
       "37            85.106383      87.234043\n",
       "38            78.723404      88.297872\n",
       "39            85.217391      87.826087\n",
       "40             84.42623       88.52459\n",
       "41             49.50495      82.178218\n",
       "42            85.217391      80.869565\n",
       "43            90.277778      91.666667"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"best_model_acc\", \"last_model_acc\"]\n",
    "Test_result = pd.DataFrame(columns=col, index=subjects)\n",
    "Test_result.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    Test_result.loc[subjects[i]] = [test_acc_best[i], test_acc_last[i]]\n",
    "\n",
    "fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "path = f'results\\CM_CW_CNN\\{fname}_Test_result.csv'\n",
    "Test_result.to_csv(path)\n",
    "print(\"Test Results\")\n",
    "Test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with PCA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>49.504950</td>\n",
       "      <td>80.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>94.444444</td>\n",
       "      <td>95.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>83.419218</td>\n",
       "      <td>87.136532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_model_acc  last_model_acc\n",
       "min        49.504950       80.869565\n",
       "max        94.444444       95.348837\n",
       "mean       83.419218       87.136532"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"with PCA\")\n",
    "dfDescript(Test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outwith PCA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>73.611111</td>\n",
       "      <td>73.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>93.055556</td>\n",
       "      <td>93.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.390244</td>\n",
       "      <td>84.371770</td>\n",
       "      <td>85.834738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subjects  best_model_acc  last_model_acc\n",
       "min    2.000000       73.611111       73.611111\n",
       "max   43.000000       93.055556       93.055556\n",
       "mean  22.390244       84.371770       85.834738"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"outwith PCA\")\n",
    "path = f'results\\CM_CW_CNN\\woPCA_Test_result.csv'\n",
    "Test_result_woPCA = pd.read_csv(path)\n",
    "dfDescript(Test_result_woPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x232234186d0>]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_losses, label=\"train\")\n",
    "# plt.plot(valid_losses, label=\"validation\")\n",
    "# plt.title(\"Losses\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_accs, label=\"train\")\n",
    "# plt.plot(valid_accs, label=\"validation\")\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
