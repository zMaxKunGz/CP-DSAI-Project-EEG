{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Brain Inverders Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braininvaders2015a.dataset import BrainInvaders2015a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainInvaders2015a()\n",
    "\n",
    "def loadData(subject, session = 'session_1', run = 'run_1'):\n",
    "    data = dataset._get_single_subject_data(subject)\n",
    "    data = data[session][run]\n",
    "    # data.set_montage(ten_twenty_montage)\n",
    "    return data\n",
    "\n",
    "data_subjects = []\n",
    "subjects = list(range(1,44))\n",
    "subjects.remove(1)\n",
    "subjects.remove(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    data_subjects.append(loadData(subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import create_info\n",
    "from mne import Epochs, find_events\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def df_to_raw(df):\n",
    "    sfreq = 512\n",
    "    ch_names = list(df.columns)\n",
    "    ch_types = ['eeg'] * (len(df.columns) - 1) + ['stim']\n",
    "    ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "    df = df.T\n",
    "      #mne looks at the tranpose() format\n",
    "    df[:-1] *= 1e-6\n",
    "      #convert from uVolts to Volts (mne assumes Volts data)\n",
    "\n",
    "    info = create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n",
    "\n",
    "    raw = mne.io.RawArray(df, info)\n",
    "    raw.set_montage(ten_twenty_montage)\n",
    "    return raw\n",
    "\n",
    "def getEpochs(raw, event_id, tmin, tmax, picks):\n",
    "\n",
    "    #epoching\n",
    "    events = find_events(raw)\n",
    "    \n",
    "    #reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "    #                       grad=4000e-13,    # 4000 fT/cm\n",
    "    #                       eeg=100e-6,       # 150 μV\n",
    "    #                       eog=250e-6)       # 250 μV\n",
    "\n",
    "    reject_criteria = dict(eeg=100e-6)  #most voltage in this range is not brain components\n",
    "\n",
    "    epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax, baseline=None, preload=True,verbose=False, picks=picks)  #8 channels\n",
    "    print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "\n",
    "    return epochs\n",
    "  \n",
    "def preprocessing(rawdata, runPCA=False):\n",
    "    # Convert and drop time column\n",
    "    data_ses1_run1_pd = rawdata.to_data_frame()\n",
    "    data_ses1_run1_pd = data_ses1_run1_pd.drop(['time'],axis = 1)\n",
    "    raw = df_to_raw(data_ses1_run1_pd)\n",
    "\n",
    "    # Notch Filter\n",
    "    raw.notch_filter(np.arange(50, 251, 50))\n",
    "\n",
    "    eeg_channels = mne.pick_types(raw.info, eeg=True)\n",
    "      \n",
    "    raw.filter(1,24,method = 'iir')\n",
    "\n",
    "\n",
    "    if runPCA:\n",
    "      raw_df = raw.to_data_frame()\n",
    "      X1 = raw_df.drop(['time'],axis = 1)\n",
    "      X = X1.drop(['STI 014'],axis = 1)\n",
    "      y = raw_df['STI 014']\n",
    "      pca = PCA(n_components=32)\n",
    "      X = pca.fit(X.values).transform(X.values)\n",
    "      y1 = y.values.reshape(-1,1)\n",
    "      data = np.hstack((X,y1))\n",
    "      df = pd.DataFrame(data, columns = list(X1.columns))\n",
    "      raw = df_to_raw(df)\n",
    "\n",
    "    event_id = {'NonTarget': 1, 'Target': 2}\n",
    "    tmin = 0.0 #0\n",
    "    tmax = 1.0 #0.5 seconds\n",
    "    picks= eeg_channels\n",
    "    epochs = getEpochs(raw,event_id, tmin, tmax, picks)\n",
    "\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 24 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 24.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=33, n_times=129472\n",
      "    Range : 0 ... 129471 =      0.000 ...   252.873 secs\n",
      "Ready.\n",
      "360 events found\n",
      "Event IDs: [1 2]\n",
      "sample drop %:  0.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "X_subjects = []\n",
    "y_subjects = []\n",
    "runPCA = True\n",
    "\n",
    "for data in data_subjects:\n",
    "    X, y = preprocessing(data, runPCA=runPCA)    \n",
    "    X_subjects.append(X)\n",
    "    y_subjects.append(y)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reshape, Convert to torch, Test/Train Split, and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "def ShapePreparing(X, y, BATCH_SIZE = 32):\n",
    "    X_reshaped = X[:, np.newaxis, :, :]\n",
    "    torch_X_reshaped = torch.from_numpy(X_reshaped)\n",
    "    torch_y = torch.from_numpy(y)\n",
    "\n",
    "    ds = TensorDataset(torch_X_reshaped, torch_y)\n",
    "\n",
    "    #Train test split\n",
    "    train_size = int(round(torch_X_reshaped.size()[0] * 0.7))\n",
    "    valid_size = int(round(torch_X_reshaped.size()[0] * 0.1))\n",
    "    test_size = int(round(torch_X_reshaped.size()[0] * 0.2))\n",
    "    sum_size = np.sum([train_size, valid_size, test_size])\n",
    "\n",
    "    # Adjust total size to equal to sample size\n",
    "    while sum_size<torch_X_reshaped.shape[0]:\n",
    "        train_size += 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    while sum_size>torch_X_reshaped.shape[0]:\n",
    "        train_size -= 1\n",
    "        sum_size = np.sum([train_size, valid_size, test_size])\n",
    "    \n",
    "    # Split data\n",
    "    train_set, valid_set, test_set = torch.utils.data.random_split(ds, [train_size, valid_size, test_size])\n",
    "\n",
    "    #Train set loader\n",
    "    train_iterator = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "    #Validation set loader\n",
    "    valid_iterator = torch.utils.data.DataLoader(dataset=valid_set, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True)\n",
    "\n",
    "    #Test set loader\n",
    "    test_iterator = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                            batch_size=test_size, \n",
    "                                            shuffle=True)\n",
    "    return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CM-CW-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_CW_CNN(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, channels, height , width)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(CM_CW_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,16,kernel_size=(32,1),stride=(1,1)))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16,16,kernel_size=(1,57),stride=(1,57)))\n",
    "        self.fc = nn.Sequential(nn.Linear(144,144),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(144,48),nn.ReLU(),nn.Dropout(0.5),\n",
    "                               nn.Linear(48,12), nn.ReLU(), nn.Dropout(0.5),\n",
    "                               nn.Linear(12,3), nn.ReLU())\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = self.conv2(x)\n",
    "        # print(\"X\",x.shape)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        # print(\"X flatten\",x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, _print=False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "\n",
    "    trues = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, labels in iterator:\n",
    "        \n",
    "        #Move tensors to the configured device\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        #check accuracy\n",
    "        predictions = model(batch.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "        if _print:\n",
    "            print('================== Predicted y ====================')\n",
    "            print(predicted)\n",
    "        predicteds.append(predicted)\n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "        if _print:\n",
    "            print('==================    True y   ====================')\n",
    "            print(labels)\n",
    "        trues.append(labels)\n",
    "        acc = 100 * (correct / total)\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc = acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc, predicteds, trues\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    predicteds = []\n",
    "    trues = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch, labels in iterator:\n",
    "            \n",
    "            #Move tensors to the configured device\n",
    "            batch = batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(batch.float())\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)  #returns max value, indices\n",
    "            predicteds.append(predicted)\n",
    "            trues.append(labels)\n",
    "            total += labels.size(0)  #keep track of total\n",
    "            correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "            acc = 100 * (correct / total)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),predicteds, trues\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def saveModel(saveName, model, type_='Best'):\n",
    "    directory = f'Result/{type(model).__name__}/{type_}/'\n",
    "    fileName = f'{saveName}.pth.tar'\n",
    "    path = directory+fileName\n",
    "    while True:\n",
    "        try:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(\"Model:{} saved.\".format(fileName))\n",
    "            break\n",
    "        except:\n",
    "            os.makedirs(directory)\n",
    "            open(path, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "\n",
    "def Training(model, train_iterator, valid_iterator, N_EPOCHS = 50, saveName=None):\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    start_time_train = time.time()\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        train_loss, train_acc, train_pred_label, train_true_label = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc, valid_pred_label, valid_true_label= evaluate(model, valid_iterator, criterion)\n",
    "        train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "        valid_losses.append(valid_loss); valid_accs.append(valid_acc)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Trainning:\", saveName)\n",
    "            print(f'Epoch: [{epoch+1:02}/{N_EPOCHS}]')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            if saveName != None:\n",
    "                saveModel(saveName, model, type_='Best')\n",
    "    if saveName != None:\n",
    "        saveModel(saveName, model, type_='Last')\n",
    "    training_time = time.time() - start_time_train\n",
    "    return train_losses, valid_losses, train_accs, valid_accs, training_time, best_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning: PCA_43\n",
      "Epoch: [100/100]\n",
      "\tTrain Loss: 0.031 | Train Acc: 96.43%\n",
      "\t Val. Loss: 0.273 |  Val. Acc: 94.44%\n",
      "Model:PCA_43.pth.tar saved.\n"
     ]
    }
   ],
   "source": [
    "train_losses_list = []\n",
    "train_accs_list = []\n",
    "valid_losses_list = []\n",
    "valid_accs_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "training_time_list = []\n",
    "best_epoch_list = []\n",
    "test_iterator_list = []\n",
    "\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Configured device: \", device)\n",
    "\n",
    "# for i in range(2):\n",
    "for i in range(len(X_subjects)):\n",
    "    # Split data\n",
    "    train_iterator, valid_iterator, test_iterator = ShapePreparing(X_subjects[i], y_subjects[i], BATCH_SIZE=64)\n",
    "    \n",
    "    # Define model\n",
    "    model = CM_CW_CNN()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    # Training\n",
    "    fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "    if subjects[i]<10:\n",
    "        filename = f'{fname}_0{str(subjects[i])}'\n",
    "    else:\n",
    "        filename = f'{fname}_{str(subjects[i])}'\n",
    "    # filename = None\n",
    "    print(filename)\n",
    "    train_losses, valid_losses, train_accs, valid_accs, training_time, best_epoch = Training(model, train_iterator, valid_iterator, N_EPOCHS = 100, saveName=filename)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator, criterion)\n",
    "    # Record results\n",
    "    train_losses_list.append(train_losses); train_accs_list.append(train_accs)\n",
    "    valid_losses_list.append(valid_losses); valid_accs_list.append(valid_accs)\n",
    "    test_loss_list.append(test_loss); test_acc_list.append(test_acc)\n",
    "    training_time_list.append(training_time); best_epoch_list.append(best_epoch)\n",
    "    test_iterator_list.append(test_iterator)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Best model ====\n",
      "max:  95.83333333333334\n",
      "min:  78.26086956521739\n",
      "mean:  84.44765593319718\n",
      "==== Last (Load) model ====\n",
      "max:  95.83333333333334\n",
      "min:  80.0\n",
      "mean:  87.70244709446828\n",
      "==== Last model ====\n",
      "max:  95.83333333333334\n",
      "min:  80.0\n",
      "mean:  87.70244709446828\n"
     ]
    }
   ],
   "source": [
    "def trainedModelLoader(path, device):\n",
    "    model = CM_CW_CNN()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model = model.float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    return model, criterion\n",
    "\n",
    "test_loss_best = []\n",
    "test_acc_best = []\n",
    "test_loss_last = []\n",
    "test_acc_last = []\n",
    "\n",
    "for i, subject in enumerate(subjects):\n",
    "    fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "    if subject<10:\n",
    "        filename = f'{fname}_0{str(subject)}'\n",
    "    else:\n",
    "        filename = f'{fname}_{str(subject)}'\n",
    "    # Best model\n",
    "    type_ = 'Best'\n",
    "    path = f'Result/CM_CW_CNN/{type_}/{filename}.pth.tar'\n",
    "    model, criterion = trainedModelLoader(path, device)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[i], criterion)\n",
    "    test_loss_best.append(test_loss)\n",
    "    test_acc_best.append(test_acc)\n",
    "    # Last model\n",
    "    type_ = 'Last'\n",
    "    path = f'Result/CM_CW_CNN/{type_}/{filename}.pth.tar'\n",
    "    model, criterion = trainedModelLoader(path, device)\n",
    "    test_loss, test_acc, test_pred_label, test_true_label = evaluate(model, test_iterator_list[i], criterion)\n",
    "    test_loss_last.append(test_loss)\n",
    "    test_acc_last.append(test_acc)\n",
    "\n",
    "\n",
    "print(\"==== Best model ====\")\n",
    "# print(test_acc_best)\n",
    "print(\"max: \", np.max(test_acc_best))\n",
    "print(\"min: \", np.min(test_acc_best))\n",
    "print(\"mean: \", np.mean(test_acc_best))\n",
    "\n",
    "print(\"==== Last (Load) model ====\")\n",
    "# print(test_acc_list)\n",
    "print(\"max: \", np.max(test_acc_last))\n",
    "print(\"min: \", np.min(test_acc_last))\n",
    "print(\"mean: \", np.mean(test_acc_last))\n",
    "\n",
    "print(\"==== Last model ====\")\n",
    "# print(test_acc_list)\n",
    "print(\"max: \", np.max(test_acc_list))\n",
    "print(\"min: \", np.min(test_acc_list))\n",
    "print(\"mean: \", np.mean(test_acc_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses_last</th>\n",
       "      <th>train_accs_last</th>\n",
       "      <th>valid_losses_last</th>\n",
       "      <th>valid_accs_last</th>\n",
       "      <th>train_losses_best</th>\n",
       "      <th>train_accs_best</th>\n",
       "      <th>valid_losses_best</th>\n",
       "      <th>valid_accs_best</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027975</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.362123</td>\n",
       "      <td>87.234043</td>\n",
       "      <td>0.543489</td>\n",
       "      <td>84.70948</td>\n",
       "      <td>0.52549</td>\n",
       "      <td>82.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.096688</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>0.173704</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.075233</td>\n",
       "      <td>92.460317</td>\n",
       "      <td>0.134743</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063937</td>\n",
       "      <td>97.359736</td>\n",
       "      <td>0.396118</td>\n",
       "      <td>97.674419</td>\n",
       "      <td>0.243644</td>\n",
       "      <td>88.448845</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>95.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079564</td>\n",
       "      <td>94.059406</td>\n",
       "      <td>1.948728</td>\n",
       "      <td>86.046512</td>\n",
       "      <td>0.70519</td>\n",
       "      <td>68.976898</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>79.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.034788</td>\n",
       "      <td>98.941799</td>\n",
       "      <td>1.230332</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.368976</td>\n",
       "      <td>88.359788</td>\n",
       "      <td>0.241854</td>\n",
       "      <td>87.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.062059</td>\n",
       "      <td>95.634921</td>\n",
       "      <td>1.140563</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>0.511765</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.667866</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.046384</td>\n",
       "      <td>94.389439</td>\n",
       "      <td>4.844704</td>\n",
       "      <td>76.744186</td>\n",
       "      <td>0.771332</td>\n",
       "      <td>65.676568</td>\n",
       "      <td>0.754622</td>\n",
       "      <td>74.418605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.041006</td>\n",
       "      <td>98.412698</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>96.296296</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>87.566138</td>\n",
       "      <td>0.16776</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.045058</td>\n",
       "      <td>97.797357</td>\n",
       "      <td>4.121998</td>\n",
       "      <td>90.625</td>\n",
       "      <td>0.54574</td>\n",
       "      <td>71.806167</td>\n",
       "      <td>0.540122</td>\n",
       "      <td>90.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.037046</td>\n",
       "      <td>98.555957</td>\n",
       "      <td>1.553116</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.245721</td>\n",
       "      <td>86.281588</td>\n",
       "      <td>0.319833</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.018339</td>\n",
       "      <td>99.236641</td>\n",
       "      <td>1.221232</td>\n",
       "      <td>88.929521</td>\n",
       "      <td>0.351686</td>\n",
       "      <td>83.358779</td>\n",
       "      <td>0.241993</td>\n",
       "      <td>87.649601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.071595</td>\n",
       "      <td>98.677249</td>\n",
       "      <td>0.651486</td>\n",
       "      <td>92.592593</td>\n",
       "      <td>0.176486</td>\n",
       "      <td>92.328042</td>\n",
       "      <td>0.218466</td>\n",
       "      <td>90.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.029631</td>\n",
       "      <td>98.511166</td>\n",
       "      <td>2.309082</td>\n",
       "      <td>84.482759</td>\n",
       "      <td>0.565272</td>\n",
       "      <td>79.404467</td>\n",
       "      <td>0.474765</td>\n",
       "      <td>84.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.057346</td>\n",
       "      <td>95.634921</td>\n",
       "      <td>2.212714</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.398822</td>\n",
       "      <td>78.968254</td>\n",
       "      <td>0.297154</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.11626</td>\n",
       "      <td>92.779783</td>\n",
       "      <td>1.59373</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.624677</td>\n",
       "      <td>69.67509</td>\n",
       "      <td>0.45264</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.031958</td>\n",
       "      <td>99.300699</td>\n",
       "      <td>1.130197</td>\n",
       "      <td>90.163934</td>\n",
       "      <td>0.471677</td>\n",
       "      <td>75.058275</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>85.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.030469</td>\n",
       "      <td>97.689769</td>\n",
       "      <td>1.248641</td>\n",
       "      <td>88.372093</td>\n",
       "      <td>0.27353</td>\n",
       "      <td>87.458746</td>\n",
       "      <td>0.256205</td>\n",
       "      <td>88.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.015804</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>1.614735</td>\n",
       "      <td>92.592593</td>\n",
       "      <td>0.359936</td>\n",
       "      <td>82.804233</td>\n",
       "      <td>0.351244</td>\n",
       "      <td>81.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.061798</td>\n",
       "      <td>98.019802</td>\n",
       "      <td>1.180576</td>\n",
       "      <td>93.023256</td>\n",
       "      <td>0.480771</td>\n",
       "      <td>78.877888</td>\n",
       "      <td>0.627969</td>\n",
       "      <td>83.72093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.067699</td>\n",
       "      <td>98.412698</td>\n",
       "      <td>0.803405</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.485757</td>\n",
       "      <td>80.15873</td>\n",
       "      <td>0.416922</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.076186</td>\n",
       "      <td>98.016997</td>\n",
       "      <td>1.049493</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.315655</td>\n",
       "      <td>84.135977</td>\n",
       "      <td>0.345907</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.466567</td>\n",
       "      <td>57.507082</td>\n",
       "      <td>0.746895</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.579503</td>\n",
       "      <td>57.223796</td>\n",
       "      <td>0.455532</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.052729</td>\n",
       "      <td>94.945848</td>\n",
       "      <td>1.084555</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.352746</td>\n",
       "      <td>76.534296</td>\n",
       "      <td>0.33725</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.041819</td>\n",
       "      <td>98.759305</td>\n",
       "      <td>1.466467</td>\n",
       "      <td>86.206897</td>\n",
       "      <td>0.41235</td>\n",
       "      <td>84.367246</td>\n",
       "      <td>0.529458</td>\n",
       "      <td>77.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.085272</td>\n",
       "      <td>99.206349</td>\n",
       "      <td>0.419539</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.447273</td>\n",
       "      <td>80.555556</td>\n",
       "      <td>0.308636</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.030587</td>\n",
       "      <td>97.286013</td>\n",
       "      <td>0.833783</td>\n",
       "      <td>86.351103</td>\n",
       "      <td>0.358644</td>\n",
       "      <td>86.847599</td>\n",
       "      <td>0.212732</td>\n",
       "      <td>86.351103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.192492</td>\n",
       "      <td>80.397022</td>\n",
       "      <td>4.170918</td>\n",
       "      <td>70.689655</td>\n",
       "      <td>0.581558</td>\n",
       "      <td>72.704715</td>\n",
       "      <td>0.671501</td>\n",
       "      <td>77.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.081668</td>\n",
       "      <td>99.118943</td>\n",
       "      <td>4.167791</td>\n",
       "      <td>90.625</td>\n",
       "      <td>0.593157</td>\n",
       "      <td>84.581498</td>\n",
       "      <td>0.84707</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.153282</td>\n",
       "      <td>89.365079</td>\n",
       "      <td>2.757272</td>\n",
       "      <td>78.836806</td>\n",
       "      <td>0.684804</td>\n",
       "      <td>65.238095</td>\n",
       "      <td>0.509467</td>\n",
       "      <td>81.510417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.113169</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.978707</td>\n",
       "      <td>86.111111</td>\n",
       "      <td>0.213775</td>\n",
       "      <td>87.698413</td>\n",
       "      <td>0.338228</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.216862</td>\n",
       "      <td>74.867725</td>\n",
       "      <td>1.235813</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.556088</td>\n",
       "      <td>62.169312</td>\n",
       "      <td>0.491309</td>\n",
       "      <td>85.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.059787</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.633868</td>\n",
       "      <td>91.489362</td>\n",
       "      <td>0.336436</td>\n",
       "      <td>85.932722</td>\n",
       "      <td>0.447485</td>\n",
       "      <td>76.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.047957</td>\n",
       "      <td>99.265786</td>\n",
       "      <td>2.00861</td>\n",
       "      <td>85.752255</td>\n",
       "      <td>0.474463</td>\n",
       "      <td>82.525698</td>\n",
       "      <td>0.491508</td>\n",
       "      <td>81.596327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.052101</td>\n",
       "      <td>97.111913</td>\n",
       "      <td>2.311949</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.515943</td>\n",
       "      <td>82.310469</td>\n",
       "      <td>0.556027</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0643</td>\n",
       "      <td>95.718654</td>\n",
       "      <td>1.974076</td>\n",
       "      <td>82.978723</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>81.039755</td>\n",
       "      <td>0.631962</td>\n",
       "      <td>74.468085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.06498</td>\n",
       "      <td>98.470948</td>\n",
       "      <td>2.816714</td>\n",
       "      <td>80.851064</td>\n",
       "      <td>0.374889</td>\n",
       "      <td>82.874618</td>\n",
       "      <td>0.354901</td>\n",
       "      <td>85.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.053853</td>\n",
       "      <td>96.029777</td>\n",
       "      <td>5.427351</td>\n",
       "      <td>84.482759</td>\n",
       "      <td>0.458541</td>\n",
       "      <td>84.119107</td>\n",
       "      <td>0.55448</td>\n",
       "      <td>79.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.094231</td>\n",
       "      <td>93.939394</td>\n",
       "      <td>1.479056</td>\n",
       "      <td>90.163934</td>\n",
       "      <td>0.412959</td>\n",
       "      <td>76.223776</td>\n",
       "      <td>0.305273</td>\n",
       "      <td>90.163934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.041727</td>\n",
       "      <td>99.150142</td>\n",
       "      <td>6.808312</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.422781</td>\n",
       "      <td>83.569405</td>\n",
       "      <td>0.680586</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.025528</td>\n",
       "      <td>97.766749</td>\n",
       "      <td>8.201634</td>\n",
       "      <td>79.310345</td>\n",
       "      <td>0.616971</td>\n",
       "      <td>83.622829</td>\n",
       "      <td>0.662423</td>\n",
       "      <td>77.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.031214</td>\n",
       "      <td>96.428571</td>\n",
       "      <td>0.273339</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.023524</td>\n",
       "      <td>96.428571</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_losses_last train_accs_last valid_losses_last valid_accs_last  \\\n",
       "subjects                                                                       \n",
       "2                 0.027975           100.0          2.362123       87.234043   \n",
       "3                 0.096688       92.857143          0.173704       97.222222   \n",
       "4                 0.063937       97.359736          0.396118       97.674419   \n",
       "5                 0.079564       94.059406          1.948728       86.046512   \n",
       "6                 0.034788       98.941799          1.230332       88.888889   \n",
       "7                 0.062059       95.634921          1.140563       86.111111   \n",
       "8                 0.046384       94.389439          4.844704       76.744186   \n",
       "9                 0.041006       98.412698          0.891084       96.296296   \n",
       "10                0.045058       97.797357          4.121998          90.625   \n",
       "11                0.037046       98.555957          1.553116            85.0   \n",
       "12                0.018339       99.236641          1.221232       88.929521   \n",
       "13                0.071595       98.677249          0.651486       92.592593   \n",
       "14                0.029631       98.511166          2.309082       84.482759   \n",
       "15                0.057346       95.634921          2.212714       88.888889   \n",
       "16                 0.11626       92.779783           1.59373            80.0   \n",
       "17                0.031958       99.300699          1.130197       90.163934   \n",
       "18                0.030469       97.689769          1.248641       88.372093   \n",
       "19                0.015804       99.206349          1.614735       92.592593   \n",
       "20                0.061798       98.019802          1.180576       93.023256   \n",
       "21                0.067699       98.412698          0.803405       88.888889   \n",
       "22                0.076186       98.016997          1.049493            90.0   \n",
       "23                0.466567       57.507082          0.746895            88.0   \n",
       "24                0.052729       94.945848          1.084555            85.0   \n",
       "25                0.041819       98.759305          1.466467       86.206897   \n",
       "26                0.085272       99.206349          0.419539       91.666667   \n",
       "28                0.030587       97.286013          0.833783       86.351103   \n",
       "29                0.192492       80.397022          4.170918       70.689655   \n",
       "30                0.081668       99.118943          4.167791          90.625   \n",
       "31                0.153282       89.365079          2.757272       78.836806   \n",
       "32                0.113169       88.888889          0.978707       86.111111   \n",
       "33                0.216862       74.867725          1.235813       88.888889   \n",
       "34                0.059787           100.0          0.633868       91.489362   \n",
       "35                0.047957       99.265786           2.00861       85.752255   \n",
       "36                0.052101       97.111913          2.311949            87.5   \n",
       "37                  0.0643       95.718654          1.974076       82.978723   \n",
       "38                 0.06498       98.470948          2.816714       80.851064   \n",
       "39                0.053853       96.029777          5.427351       84.482759   \n",
       "40                0.094231       93.939394          1.479056       90.163934   \n",
       "41                0.041727       99.150142          6.808312            78.0   \n",
       "42                0.025528       97.766749          8.201634       79.310345   \n",
       "43                0.031214       96.428571          0.273339       94.444444   \n",
       "\n",
       "         train_losses_best train_accs_best valid_losses_best valid_accs_best  \n",
       "subjects                                                                      \n",
       "2                 0.543489        84.70948           0.52549       82.978723  \n",
       "3                 0.075233       92.460317          0.134743       94.444444  \n",
       "4                 0.243644       88.448845            0.1781       95.348837  \n",
       "5                  0.70519       68.976898          0.625523       79.069767  \n",
       "6                 0.368976       88.359788          0.241854       87.037037  \n",
       "7                 0.511765       77.777778          0.667866       77.777778  \n",
       "8                 0.771332       65.676568          0.754622       74.418605  \n",
       "9                 0.330357       87.566138           0.16776       96.296296  \n",
       "10                 0.54574       71.806167          0.540122          90.625  \n",
       "11                0.245721       86.281588          0.319833            87.5  \n",
       "12                0.351686       83.358779          0.241993       87.649601  \n",
       "13                0.176486       92.328042          0.218466       90.740741  \n",
       "14                0.565272       79.404467          0.474765       84.482759  \n",
       "15                0.398822       78.968254          0.297154       86.111111  \n",
       "16                0.624677        69.67509           0.45264            77.5  \n",
       "17                0.471677       75.058275          0.345175       85.245902  \n",
       "18                 0.27353       87.458746          0.256205       88.372093  \n",
       "19                0.359936       82.804233          0.351244       81.481481  \n",
       "20                0.480771       78.877888          0.627969        83.72093  \n",
       "21                0.485757        80.15873          0.416922       86.111111  \n",
       "22                0.315655       84.135977          0.345907            90.0  \n",
       "23                0.579503       57.223796          0.455532            84.0  \n",
       "24                0.352746       76.534296           0.33725            82.5  \n",
       "25                 0.41235       84.367246          0.529458       77.586207  \n",
       "26                0.447273       80.555556          0.308636       88.888889  \n",
       "28                0.358644       86.847599          0.212732       86.351103  \n",
       "29                0.581558       72.704715          0.671501       77.586207  \n",
       "30                0.593157       84.581498           0.84707           81.25  \n",
       "31                0.684804       65.238095          0.509467       81.510417  \n",
       "32                0.213775       87.698413          0.338228       86.111111  \n",
       "33                0.556088       62.169312          0.491309       85.185185  \n",
       "34                0.336436       85.932722          0.447485       76.595745  \n",
       "35                0.474463       82.525698          0.491508       81.596327  \n",
       "36                0.515943       82.310469          0.556027            80.0  \n",
       "37                0.683168       81.039755          0.631962       74.468085  \n",
       "38                0.374889       82.874618          0.354901       85.106383  \n",
       "39                0.458541       84.119107           0.55448       79.310345  \n",
       "40                0.412959       76.223776          0.305273       90.163934  \n",
       "41                0.422781       83.569405          0.680586            82.0  \n",
       "42                0.616971       83.622829          0.662423       77.586207  \n",
       "43                0.023524       96.428571          0.000281           100.0  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"train_losses_last\", \"train_accs_last\", \"valid_losses_last\", \"valid_accs_last\", \n",
    "    \"train_losses_best\", \"train_accs_best\", \"valid_losses_best\", \"valid_accs_best\"]\n",
    "train_result = pd.DataFrame(columns=col, index=subjects)\n",
    "train_result.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    b = best_epoch_list[i]\n",
    "    train_result.loc[subjects[i]] = [\n",
    "        train_losses_list[i][-1], train_accs_list[i][-1], \n",
    "        valid_losses_list[i][-1], valid_accs_list[i][-1],\n",
    "        train_losses_list[i][b], train_accs_list[i][b], \n",
    "        valid_losses_list[i][b], valid_accs_list[i][b],\n",
    "    ]\n",
    "\n",
    "fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "path = f'Result\\CM_CW_CNN\\{fname}_Train_result.csv'\n",
    "train_result.to_csv(path)\n",
    "print(\"Training Results\")\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses_last</th>\n",
       "      <th>train_accs_last</th>\n",
       "      <th>valid_losses_last</th>\n",
       "      <th>valid_accs_last</th>\n",
       "      <th>train_losses_best</th>\n",
       "      <th>train_accs_best</th>\n",
       "      <th>valid_losses_best</th>\n",
       "      <th>valid_accs_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.015804</td>\n",
       "      <td>57.507082</td>\n",
       "      <td>0.173704</td>\n",
       "      <td>70.689655</td>\n",
       "      <td>0.023524</td>\n",
       "      <td>57.223796</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>74.418605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.466567</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8.201634</td>\n",
       "      <td>97.674419</td>\n",
       "      <td>0.771332</td>\n",
       "      <td>96.428571</td>\n",
       "      <td>0.847070</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.075164</td>\n",
       "      <td>95.066310</td>\n",
       "      <td>2.035961</td>\n",
       "      <td>87.246981</td>\n",
       "      <td>0.437690</td>\n",
       "      <td>80.508769</td>\n",
       "      <td>0.428548</td>\n",
       "      <td>84.505082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_losses_last  train_accs_last  valid_losses_last  valid_accs_last  \\\n",
       "min            0.015804        57.507082           0.173704        70.689655   \n",
       "max            0.466567       100.000000           8.201634        97.674419   \n",
       "mean           0.075164        95.066310           2.035961        87.246981   \n",
       "\n",
       "      train_losses_best  train_accs_best  valid_losses_best  valid_accs_best  \n",
       "min            0.023524        57.223796           0.000281        74.418605  \n",
       "max            0.771332        96.428571           0.847070       100.000000  \n",
       "mean           0.437690        80.508769           0.428548        84.505082  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dfDescript(x):\n",
    "    return pd.DataFrame(index=['min','max', 'mean'], data=[x.min(), x.max(), x.mean()])\n",
    "\n",
    "dfDescript(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.297872</td>\n",
       "      <td>88.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.833333</td>\n",
       "      <td>95.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.209302</td>\n",
       "      <td>90.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.72093</td>\n",
       "      <td>88.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.962963</td>\n",
       "      <td>89.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.55814</td>\n",
       "      <td>87.209302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.666667</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84.615385</td>\n",
       "      <td>93.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84.810127</td>\n",
       "      <td>84.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90.374332</td>\n",
       "      <td>91.97861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91.666667</td>\n",
       "      <td>87.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>79.130435</td>\n",
       "      <td>83.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84.722222</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>83.544304</td>\n",
       "      <td>86.075949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>81.147541</td>\n",
       "      <td>86.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86.046512</td>\n",
       "      <td>86.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80.555556</td>\n",
       "      <td>85.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>80.232558</td>\n",
       "      <td>90.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>83.168317</td>\n",
       "      <td>81.188119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>85.148515</td>\n",
       "      <td>85.148515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84.810127</td>\n",
       "      <td>93.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78.26087</td>\n",
       "      <td>84.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>80.555556</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>84.671533</td>\n",
       "      <td>86.131387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>84.347826</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>80.0</td>\n",
       "      <td>84.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>83.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>86.111111</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>87.234043</td>\n",
       "      <td>89.361702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>87.113402</td>\n",
       "      <td>84.536082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>78.481013</td>\n",
       "      <td>84.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>81.914894</td>\n",
       "      <td>87.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>82.978723</td>\n",
       "      <td>88.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80.869565</td>\n",
       "      <td>84.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>78.688525</td>\n",
       "      <td>90.163934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>83.168317</td>\n",
       "      <td>88.118812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>84.347826</td>\n",
       "      <td>87.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>93.055556</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         best_model_acc last_model_acc\n",
       "subjects                              \n",
       "2             88.297872      88.297872\n",
       "3             95.833333      95.833333\n",
       "4             87.209302      90.697674\n",
       "5              83.72093      88.372093\n",
       "6             87.962963      89.814815\n",
       "7             83.333333      86.111111\n",
       "8              82.55814      87.209302\n",
       "9             91.666667      91.666667\n",
       "10            84.615385      93.846154\n",
       "11            84.810127      84.810127\n",
       "12            90.374332       91.97861\n",
       "13            91.666667      87.037037\n",
       "14            79.130435      83.478261\n",
       "15            84.722222           87.5\n",
       "16            83.544304      86.075949\n",
       "17            81.147541      86.065574\n",
       "18            86.046512      86.046512\n",
       "19            80.555556      85.185185\n",
       "20            80.232558      90.697674\n",
       "21            83.333333      88.888889\n",
       "22            83.168317      81.188119\n",
       "23            85.148515      85.148515\n",
       "24            84.810127      93.670886\n",
       "25             78.26087      84.347826\n",
       "26            80.555556      94.444444\n",
       "28            84.671533      86.131387\n",
       "29            84.347826           80.0\n",
       "30                 80.0      84.615385\n",
       "31            83.333333      83.888889\n",
       "32            83.333333           87.5\n",
       "33            86.111111      88.888889\n",
       "34            87.234043      89.361702\n",
       "35            87.113402      84.536082\n",
       "36            78.481013      84.810127\n",
       "37            81.914894      87.234043\n",
       "38            82.978723      88.297872\n",
       "39            80.869565      84.347826\n",
       "40            78.688525      90.163934\n",
       "41            83.168317      88.118812\n",
       "42            84.347826      87.826087\n",
       "43            93.055556      91.666667"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"best_model_acc\", \"last_model_acc\"]\n",
    "Test_result = pd.DataFrame(columns=col, index=subjects)\n",
    "Test_result.index.name = \"subjects\"\n",
    "\n",
    "for i in range(len(train_losses_list)):\n",
    "    Test_result.loc[subjects[i]] = [test_acc_best[i], test_acc_last[i]]\n",
    "\n",
    "fname = \"PCA\" if runPCA else \"woPCA\"\n",
    "path = f'Result\\CM_CW_CNN\\{fname}_Test_result.csv'\n",
    "Test_result.to_csv(path)\n",
    "print(\"Test Results\")\n",
    "Test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with PCA True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>78.260870</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.833333</td>\n",
       "      <td>95.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>84.447656</td>\n",
       "      <td>87.702447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      best_model_acc  last_model_acc\n",
       "min        78.260870       80.000000\n",
       "max        95.833333       95.833333\n",
       "mean       84.447656       87.702447"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"with PCA\", runPCA)\n",
    "dfDescript(Test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>best_model_acc</th>\n",
       "      <th>last_model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>78.260870</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>95.833333</td>\n",
       "      <td>95.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.390244</td>\n",
       "      <td>84.447656</td>\n",
       "      <td>87.702447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subjects  best_model_acc  last_model_acc\n",
       "min    2.000000       78.260870       80.000000\n",
       "max   43.000000       95.833333       95.833333\n",
       "mean  22.390244       84.447656       87.702447"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"PCA\")\n",
    "path = f'Result/CM_CW_CNN/PCA_Test_result.csv'\n",
    "Test_result_woPCA = pd.read_csv(path)\n",
    "dfDescript(Test_result_woPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_losses, label=\"train\")\n",
    "# plt.plot(valid_losses, label=\"validation\")\n",
    "# plt.title(\"Losses\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_accs, label=\"train\")\n",
    "# plt.plot(valid_accs, label=\"validation\")\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
